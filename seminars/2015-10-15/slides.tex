%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Beamer Presentation
% LaTeX Template
% Version 1.0 (10/11/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND THEMES
%----------------------------------------------------------------------------------------

\documentclass{beamer}

\mode<presentation> {

% The Beamer class comes with a number of default slide themes
% which change the colors and layouts of slides. Below this is a list
% of all the themes, uncomment each in turn to see what they look like.

%\usetheme{default}
%\usetheme{AnnArbor}
%\usetheme{Antibes}
%\usetheme{Bergen}
%\usetheme{Berkeley}
%\usetheme{Berlin}
%\usetheme{Boadilla}
%\usetheme{CambridgeUS}
\usetheme{Copenhagen}
%\usetheme{Darmstadt}
%\usetheme{Dresden}
%\usetheme{Frankfurt}
%\usetheme{Goettingen}
%\usetheme{Hannover}
%\usetheme{Ilmenau}
%\usetheme{JuanLesPins}
%\usetheme{Luebeck}
%\usetheme{Madrid}
%\usetheme{Malmoe}
%\usetheme{Marburg}
%\usetheme{Montpellier}
%\usetheme{PaloAlto}
%\usetheme{Pittsburgh}
%\usetheme{Rochester}
%\usetheme{Singapore}
%\usetheme{Szeged}
%\usetheme{Warsaw}

% As well as themes, the Beamer class has a number of color themes
% for any slide theme. Uncomment each of these in turn to see how it
% changes the colors of your current slide theme.

%\usecolortheme{albatross}
%\usecolortheme{beaver}
%\usecolortheme{beetle}
%\usecolortheme{crane}
%\usecolortheme{dolphin}
%\usecolortheme{dove}
%\usecolortheme{fly}
%\usecolortheme{lily}
%\usecolortheme{orchid}
%\usecolortheme{rose}
%\usecolortheme{seagull}
%\usecolortheme{seahorse}
%\usecolortheme{whale}
%\usecolortheme{wolverine}

%\setbeamertemplate{footline} % To remove the footer line in all slides uncomment this line
%\setbeamertemplate{footline}[page number] % To replace the footer line in all slides with a simple slide count uncomment this line

%\setbeamertemplate{navigation symbols}{} % To remove the navigation symbols from the bottom of all slides uncomment this line
}

\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule
                      % in tables

\input{../../physics_common}
\renewcommand{\P}{
\mathbb P
}

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title{Eigenvalues of a fixed-dimensional heavy-tailed matrix} % The
                                % short title appears at the bottom of
                                % every slide, the full title is only
                                % on the title page

\author{Xie Xiaolei} % Your name
\institute[UCPH] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
{
Copenhagen University  \\ % Your institution for the title page
\medskip
\textit{xie.xiaolei@gmail.com} % Your email address
}
\date{\today} % Date, can be changed to a custom date

\begin{document}

\begin{frame}
\titlepage % Print the title page as the first slide
\end{frame}

% \begin{frame}
% \frametitle{Overview}
% \tableofcontents
% \end{frame}

%----------------------------------------------------------------------------------------
%	PRESENTATION SLIDES
%----------------------------------------------------------------------------------------
% \section{Simple dependence models}
%------------------------------------------------
\section[iid data]{$X_{it}$ are iid.}
\subsection{Approximating Sample Covariance Matrices}
\begin{frame}
  \frametitle{$X_{it}$ are iid.}
  Let $\mathbf X = (X_{it})_{i=1,\dots,p; t = 1,\dots, n}$ be sequences of iid. r.v.
  \[
  (\mathbf{XX'})_{ij} = \sum_{t=1}^n X_{it}X_{jt}
  \]
  Assume $\E X = 0$ if $\E |X| < \infty$. Define $a_n$ such that
  \begin{eqnarray*}
    \P(|Z| > a_n) &=& 1/n  \\
    a_n &\sim& n^{1/\alpha} l(n) \text{ where } l(n) \in \mathcal R_{0}
  \end{eqnarray*}
  Let $L(\cdot)$ be slowly varying whose form is of no interest.
  \[
  \lambda_{(1)} \geq \lambda_{(2)} \geq \cdots \geq \lambda_{(p)}
  \]
  are eigenvalues of $\mathbf{XX'}$ when $\alpha \in (0, 2)$ and those of $\mathbf{XX'}
  - \E \mathbf{XX'}$ when $\alpha \in (2, 4)$.
\end{frame}

% \begin{frame}
%   \frametitle{$X_{it}$ are iid.}
%   Later we show $\lambda_{(i)} \overset{d}{\to} \xi_{(i)} \sim
%   S_{\alpha/2}$, where $\xi_{(i)}$ is the $i$-th largest order
%   statistic of an iid. sample of $\alpha/2$-stable distribution. An
%   $\alpha$-stable distribution, denoted $S_{\alpha}$ here 
% \end{frame}

\begin{frame}
  \frametitle{$X_{it}$ are iid}
  \begin{itemize}
  \item when $0 < \alpha  < 2$ the large deviation results of Cline
    and Hsing \cite{cline:hsing:1998} gives, for $i \neq j$
    \[
    \P(a_n^{-2} |\sum_{t=1}^n X_{it}X_{jt}| > \epsilon) \sim n
    \P(|X_{it}X_{jt}| > \epsilon a_n^2)
    \]
    According to Embrechts and Goldie \cite{Embrechts1982263},
    $X_{it}X_{jt} \in \mathcal R_{-\alpha}$, hence
    \[
    \P(a_n^{-2} |\sum_{t=1}^n X_{it}X_{jt}| > \epsilon) \sim n
    [n^{2/\alpha} L(n)]^{-\alpha} \sim n^{-1} L(n) \to 0
    \]
    for $i = j$, CLT yields
    \[
    a_n^{-2} \sum_{t=1}^n X_{it}^2 \overset{d}{\to} \xi_i \sim S_{\alpha/2}
    \]
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{$X_{it}$ are iid.}
  \begin{itemize}
  \item when $2 < \alpha < 4$, CLT gives, for $i \neq j$
    \begin{eqnarray*}
      n^{-1/2} \sum_{t=1}^n X_{it}X_{jt} &\overset{d}{\to}& N(0, (\E X^2)^2)
    \end{eqnarray*}
    and, also by CLT
    \[
    a_n^{-2}(\sum_{t=1}^n X_{it}^2 - n \E X^2) \overset{d}{\to} \xi_i
    \sim S_{\alpha/2}
    \]
    but
    \[
    {n^{1/2} \over a_n^2} \sim {n^{-2/\alpha + 1/2} \over L(n)} \to 0
    \]
    Note $2 < \alpha < 4$ and hence $2/\alpha > 1/2$.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{$X_{it}$ are iid.}
  Thus Weyl's perturbation theorem gives
  \begin{itemize}
  \item when $0 < \alpha < 2$
    \begin{eqnarray*}
    && \max_{i=1,\dots,p} a_n^{-2} |\lambda_{(i)}(\mathbf{XX'}) - \lambda_{(i)}(\diag(\mathbf{XX'}))| \\
    &\leq& a_n^{-2} \|\mathbf{XX'} - \diag(\mathbf{XX'})\|_2 \\
    &\leq& a_n^{-2} \max_{i=1,\dots,p} \left|\sum_{j\neq i} (\mathbf{XX'})_{ij}\right|
    \overset{P}{\to} 0
    \end{eqnarray*}
  \item when $2 < \alpha < 4$, by similar arguments
    \begin{eqnarray*}
      \max_{i=1,\dots,p} a_n^{-2} |\lambda_{(i)}(\mathbf{XX'} - \E \mathbf{XX'}) -
      \lambda_{(i)}(\diag(\mathbf{XX'} - \E \mathbf{XX'}))|
      &\overset{P}{\to}& 0
    \end{eqnarray*}
  \end{itemize}
\end{frame}

\subsection{Distribution of the Determinant}
\begin{frame}
\frametitle{Distribution of the determinant}
When the data matrix has iid entries, $a_n^{-2} \lambda_{(i)} \overset{d}{\to}
\xi_{(i)}$, $\xi \sim S_{\alpha/2}$, where $\lambda_{(i)}$ denotes
the $i$-th largest eigenvalue of $H = \mathbf{XX'}$ when $0 < \alpha < 2$ and that
of $H = \mathbf{XX'} - \E \mathbf{XX'}$ when $2 < \alpha < 4$. According to Samorodnitsky and
Taqqu\cite{SamorodnitskyTaqqu1994} Theorem 4.4.1
$$
\P(\xi > x) \sim x^{-\alpha/2} C_{\alpha/2}
$$
as $x \to \infty$ and $n \to \infty$. $C_{\alpha/2}$ is a constant
dependent only on $\alpha$.
\end{frame}

\begin{frame}
  \frametitle{Distribution of the determinant}
  \begin{eqnarray*}
    \lim_{n \to \infty} a_n^{-2p} \det(H) &=& \lim_{n \to \infty}
    \prod_{i=1}^p a_n^{-2} \lambda_{(i)} \nonumber \\
    &\overset{d}{=}& \prod_{i=1}^p \xi_{i} \label{eq:a}
  \end{eqnarray*}
  Because RHS of \eqref{eq:a} is a product of iid r.v. with Pareto
  tails, we have
  \[
  \P\left(
    \prod_{i=1}^p \xi_{i} > x
  \right) \sim {\alpha^{p-1} C_{\alpha/2}^p \over (p-1)!}  x^{-\alpha/2} \log^{p-1} x 
  \text{, as } x \to \infty
  \]
\end{frame}

\begin{frame}
  \frametitle{Distribution of the eigenvalue Spacings}
  Consider the joint distribution of
  \[
  a_n^{-2}(\lambda_{(1)} - \lambda_{(2)}, \lambda_{(2)} - \lambda_{(3)},
  \dots, \lambda_{(p-1)} - \lambda_{(p)})
  \]
  Let $F(x) = \P(\xi \leq x)$. $\bar{F}(x) \sim x^{-\alpha/2}
  C_{\alpha/2}$
Then
\begin{eqnarray*}
\frac{\partial^p}{\partial x_1\partial x_2 \cdots \partial x_p}
\P(\xi_1 \leq x_1, \xi_2 \leq x_2, \dots, \xi_p \leq x_p)
&=& p! \prod_{i=1}^p F'(x_i)
\end{eqnarray*}
where acoording to Zolotarev \cite{Zolotarev1983} theorem 2.5.2
\begin{eqnarray*}
  F'(x) &\sim& {\nu \over \sqrt{\pi \alpha}} \left(2y/\alpha\right)^{2/\alpha - 1/2}
  e^{-y} \left[
    1 + \sum_{n=1}^\infty Q_n(\alpha_*) (\alpha_* y)^{-n}
  \right] \\
  y &=& |1 - \alpha/2|(2x/\alpha)^{2\alpha/(2\alpha-1)}\\
  \alpha_* &=& \max\{2/\alpha, \alpha/2\} \\
  \nu &=& |1 - \alpha/2|^{-2/\alpha}
\end{eqnarray*}
\end{frame}

% \begin{frame}
%   \frametitle{Distribution of the eigenvalue Spacings}
%   Denote the spacings as $(s_1, \dots, s_p) = a_n^{-2} (\lambda_{(1)} - \lambda_{(2)}, \dots,
%   \lambda_{(p-1)} - \lambda_{(p)}, \lambda_{(p)})$, and denote their joint density function as
%   $f_s(s_1, \dots, s_p)$. Then $\lambda_{(i)} = \sum_{j=i}^p s_j$ and we may write
%   \begin{eqnarray*}
%     f_s(s_1, \dots, s_p) &=& p! \prod_{i=1}^p
%       F'\left(\sum_{j=i}^p s_j\right)
%   \end{eqnarray*}
%   This is to be compared with the case when $p,n \to \infty$. In that
%   case
%   $$
  
%   $$
% \end{frame}

\section[dependent data]{Dependent Data}
\subsection{auto- and cross-correlated data}
\begin{frame}
\frametitle{$X_{it} = \theta Z_{i, t-1} + Z_{i, t}$}
Consider a data matrix $X$ each of whose rows comprises an MA(1) process:
$$
X_{it} = \theta Z_{i, t-1} + Z_{i, t}
$$
where $Z_{i,t} \in \mathcal R_{-\alpha}$ are iid. It is shown
$$
a_n^{-2} \|\mathbf{XX'} - \text{diag}(\mathbf{XX'})\|_2 \overset{P}{\to} 0
$$
For $i \neq j$
\begin{eqnarray*}
  a_n^{-2}(XX')_{ij} &=& a_n^{-2} \sum_{t=1}^n Z_{it} Z_{jt} +
  a_n^{-2} \theta \sum_{t=1}^n Z_{it} Z_{j,t-1} \\
  && +\theta a_n^{-2} \sum_{t=1}^n Z_{i, t-1}
  Z_{j,t} + \theta^2 a_n^{-2} \sum_{t=1}^n Z_{i,t-1} Z_{j,t-1}
\end{eqnarray*}
\end{frame}

\begin{frame}
  \frametitle{$X_{it} = \theta Z_{i, t-1} + Z_{i, t}$}
  $$
  a_n^{-2}\text{diag}(\mathbf{XX'}) = a_n^{-2} (1+\theta^2)
  \begin{pmatrix}
    \sum_{t=1}^n Z_{1t}^2 & 0 & \cdots & 0 \\
    0 & \sum_{t=1}^n Z_{2t}^2 & \cdots & 0 \\
    \vdots & \ddots & \vdots & \vdots \\
    0 & 0 & \cdots & \sum_{t=1}^n Z_{pt}^2
  \end{pmatrix}
  $$
\end{frame}
%------------------------------------------------

\begin{frame}
  \frametitle{$X_{it} = \varphi Z_{i-1, t} + Z_{i,t}$}
  Here
  \begin{footnotesize}
    \begin{eqnarray*}
      (XX')_{ij} &=& \sum_{t=1}^n (Z_{it} + \varphi Z_{i-1,t})(Z_{jt} +
      \varphi Z_{j-1,t}) \\
      &=& \sum_{t=1}^n (Z_{it}^2 + \varphi^2 Z_{i-1,t}^2)\I{i=j}
      + \sum_{t=1}^n (Z_{it}Z_{jt}+\varphi^2 Z_{i-1,t}Z_{j-1,t})\I{i\neq j}
      \\
      && + \varphi \sum_{t=1}^n Z_{it}^2 \I{i=j-1} 
      +\varphi\sum_{t=1}^n Z_{it} Z_{j-1,t}\I{i\neq j-1} \\
      && + \varphi \sum_{t=1}^n Z_{i-1,t}^2 \I{i=j+1} 
      +\varphi\sum_{t=1}^n Z_{jt} Z_{i-1,t}\I{i\neq j+1} \\
    \end{eqnarray*}
  \end{footnotesize}
\end{frame}

\begin{frame}
  \frametitle{$X_{it} = \varphi Z_{i-1, t} + Z_{i,t}$}
  \begin{itemize}
  \item if $0 < \alpha < 2$
    \[
    a_n^{-2} XX' \overset{d}{\to} A
    \]
  \item if $2 < \alpha < 4$
    \[
    a_n^{-2} (XX' - \E XX' ) \overset{d}{\to} A
    \]
  \end{itemize}
  where
  \begin{footnotesize}
    \[
    A =
    \begin{pmatrix}
      \xi_1 + \varphi^2 \xi_0 & \varphi \xi_1 & 0 & \cdots & 0 \\
      \varphi \xi_1 & \xi_2 + \varphi^2 \xi_1 & \varphi \xi_2 & \cdots & 0 \\
      0 & \varphi \xi_2 & \xi_3 + \varphi^2 \xi_2 & \cdots & 0 \\
      \vdots & \vdots & \vdots & \ddots & \vdots \\
      0 & 0 & 0 & \cdots & \xi_p + \varphi^2 \xi_{p-1}
    \end{pmatrix}
    \]
    Here $a_n^{-2}\sum_{t=1}^n Z_{it}^2 \overset{d}{\to} \xi_i \sim
    S_{\alpha/2}$ or $a_n^{-2}\left(\sum_{t=1}^n Z_{it}^2 - n \E
      Z^2\right) \overset{d}{\to} \xi_i \sim S_{\alpha/2}$
  \end{footnotesize}
\end{frame}

\begin{frame}
  \frametitle{$X_{it} = \sum_{k=0}^\infty \sum_{l=0}^\infty h_{kl}
    Z_{i-k,t-l}$}
  Similar to the previous case
  \begin{itemize}
  \item if $0 < \alpha < 2$
    \[
    a_n^{-2} XX'  \overset{d}{\to} A 
    \]
  \item if $2 < \alpha < 4$
    \[
    a_n^{-2} (XX' - \E XX' ) \overset{d}{\to} A
    \]
  \end{itemize}
  where
  \begin{footnotesize}
    \begin{eqnarray*}
      A &=& \sum_{k=0}^\infty \sum_{l=0}^\infty h_{kl}
      \begin{pmatrix}
        h_{kl} \xi_{1-k} & 
        h_{k+1,l} \xi_{1-k} & 
        h_{k+2,l} \xi_{1-k} & \cdots & h_{k+p-1,l}
        \xi_{1-k}\\
        h_{k+1,l} \xi_{1-k} &
        h_{kl} \xi_{2-k} & 
        h_{k+1,l} \xi_{2-k} & \cdots & h_{k+p-2,l}
        \xi_{2-k}\\
        h_{k+2,l} \xi_{1-k} &
        h_{k+1,l} \xi_{2-k} & 
        h_{kl} \xi_{3-k} & \cdots &
        h_{k+p-3,l} \xi_{3-k}\\
        \vdots & \vdots & \vdots & \ddots & \vdots \\
        h_{k+p-1} \xi_{1-k} & h_{k+p-2} \xi_{2-k} &
        h_{k+p-3} \xi_{3-k} & \cdots & h_{kl} \xi_{p-k}
      \end{pmatrix}
    \end{eqnarray*}
  \end{footnotesize}
\end{frame}

\subsection{Stochastic Volatility data}
Consider the model
\[
X_{it} = \sigma_{it} Z_{it}
\]
where
\begin{enumerate}
\item $Z_{it} \in \mathcal R_{-\alpha}$, independent of $\sigma_{it}$
\item $\E Z = 0$
\item $\sigma_{it}$ strictly stationary
\item $\E \sigma_{i,0}^q < \infty$ for some $q > 2\alpha$
\item $\sigma_{it}$ is strongly mixing with rate $\alpha_j \leq c
  j^{-a}$ for some $a > \max\{1, {(\alpha - 2) q \over 2 q - \alpha}\}$.
\end{enumerate}
On these conditions, it can be shown, for $i \neq j$
\[
a_n^{-2 }(\mathbf{XX'})_{ij} \overset{P}{\to} 0
\]
Thus the eigenvalues of $a_n^{-2 } \mathbf{XX'}$ can be approximated by those
of $\diag(\mathbf{XX'})$.

\begin{frame}
  \frametitle{Sketch of the proof}
  For $i \neq j$, $    a_n^{-2} (\mathbf{XX'})_{ij} = a_n^{-2} \sum_{t=1}^n
  \sigma_{it} \sigma_{jt} Z_{it} Z_{jt}$. The large deviation result
  of Mikosch and Wintenberger gives
  \begin{eqnarray*}
    && \P\left(
      \left|\sum_{t=1}^n \sigma_{it} \sigma_{jt} Z_{it} Z_{jt}\right| > a_n^2 \epsilon
    \right) \\
    &\sim& n \P(|\sigma_{it} \sigma_{jt} Z_{it} Z_{jt}| > a_n^2
    \epsilon) \\
    &\sim& \E |\sigma_{it} \sigma_{jt}|^\alpha n
    (n^{2/\alpha})^{-\alpha} L(n) \to 0
  \end{eqnarray*}
Work is still ongoing to prove the same convergence to 0 in
probability on a condition weaker than strong mixing.
\end{frame}
\bibliographystyle{unsrt}
\bibliography{../../thesis/econophysics}
\end{document} 
