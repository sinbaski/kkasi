\documentclass{report}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{enumerate}
% \usepackage{bookmark}

\input{../physics_common.tex}
\author{Xie Xiaolei}
\date{\today}
\title{Solutions to the Final Term Test}
\begin{document}
\maketitle

\begin{enumerate}[1.]
\item
  \begin{enumerate}[(a)]
  \item We consider the probability
    \begin{eqnarray*}
      && P(X_i < x) \\
      &=& P(\bigcap_{j=1}^k \{Y_{i+j} \le x\}) \\
    \end{eqnarray*}
    Since the $(Y_i)$ are iid with df. $F^{1/k}$, we have
    \begin{eqnarray*}
      && P(\bigcap_{j=1}^k \{Y_{i+j} \le x\}) \\
      &=& [F^{1/k}(x)]^k \\
      &=& F(x) \\
    \end{eqnarray*}
    The distribution function of $X_i$ is $F(x)$.

  \item We want to prove, $\forall n \ge 1, \forall h \ge 1$, $(X_1,
    \cdots, X_n) \ed (X_{1+h}, \cdots, X_{n+h})$.

    When $n = 1$, this is already proven in the solution to the last
    question since $X_i \sim F$, for any $i$.

    Now suppose $(X_1, \cdots, X_n) \ed (X_{1+h}, \cdots, X_{n+h})$
    for some $n \ge 1$ and $\forall h \ge 1$. In the following we
    prove 
    \[
    (X_1, \cdots, X_{n+1}) \ed (X_{1+h}, \cdots, X_{n+1+h})
    \]
    
    In fact we only need to prove the statement for $h=1$. Because
    $(Y_i)$ is an iid sequence, we can always remove the first element
    and relabel the sequence so that the old $Y_{i+1}$ is the new
    $Y_{i}$. Applying the statement for $h=1$ gives $(X_2, \cdots,
    X_{n+1}) \ed (X_{3}, \cdots, X_{n+2})$ with the old indices,
    thus establishing the statement for $h=2$. This procedure can be
    repeated, proving the statement for all values of $h$.

    In the case $h=1$, we need to prove
    \begin{eqnarray*}
      && P\left[(X_1 \le a_1, \cdots, X_{n+1} \le a_{n+1}) \le (a_1,
        \cdots, a_{n+1}) \right] \\
      &=& P\left[(X_2 \le a_1, \cdots, X_{n+2} \le a_{n+1}) \right]
    \end{eqnarray*}
    We may write
    \begin{eqnarray*}
      && P(X_1 \le a_1, \cdots, X_{n+1} \le a_{n+1}) \\
      &=& P(X_{n+1} \le a_{n+1} | X_1 \le a_1, \cdots, X_{n} \le
      a_{n}) \cdot \\
      && P(X_1 \le a_1, \cdots, X_{n} \le a_{n})
    \end{eqnarray*}
    \begin{eqnarray*}
      && P(X_{n+1} \le a_{n+1} | X_1 \le a_1, \cdots, X_{n} \le
      a_{n}) \\
      &=& P(Y_{n+2} \le a_{n+1}, \cdots, Y_{n+k+1} \le a_{n+1} | Y_2
      \le b_1, \cdots, Y_{n+k} \le b_{n+k-1})
    \end{eqnarray*}
    where $b_1, \cdots, b_{n+k-1}$ are constants depending on $a_1,
    \cdots, a_n$. Because $(Y_i)$ are iid, the above conditional
    probability can be factorized
    \begin{eqnarray*}
      && P(Y_{n+2} \le a_{n+1}, \cdots, Y_{n+k+1} \le a_{n+1} | Y_2
      \le b_1, \cdots, Y_{n+k} \le b_{n+k-1}) \\
      &=& P(Y_{n+2} \le a_{n+1} | Y_{n+2} \le b_{n+1}) \cdots
      P(Y_{n+k} \le a_{n+1} | Y_{n+k} \le b_{n+k-1}) \cdot \\
      && P(Y_{n+k+1} \le a_{n+1}) \\
      &=& {F^{1/k}(a_{n+1} \wedge b_{n+1}) \over F^{1/k}(b_{n+1})} \cdots
      {F^{1/k}(a_{n+1} \wedge b_{n+k-1}) \over F^{1/k}(b_{n+k-1})}
      F^{1/k}(a_{n+1})
    \end{eqnarray*}
    
    In comparison,
    \begin{eqnarray*}
      && P(X_2 \le a_1, \cdots, X_{n+2} \le a_{n+1}) \\
      &=& P(X_{n+2} \le a_{n+1} | X_2 \le a_1, \cdots, X_{n+1} \le
      a_{n}) \cdot \\
      && P(X_2 \le a_1, \cdots, X_{n+1} \le a_{n})
    \end{eqnarray*}
    By assumption, $(X_2, \cdots, X_{n+1}) \ed (X_1, \cdots, X_{n})$,
    meaning
    \[
    P(X_2 \le a_1, \cdots, X_{n+1} \le a_{n}) = P(X_1 \le
    a_1, \cdots, X_{n} \le a_{n})
    \]
    It remains to establish
    \begin{eqnarray*}
    && P(X_{n+2} \le a_{n+1} | X_2 \le a_1, \cdots, X_{n+1} \le
    a_{n}) \\
    &=& P(X_{n+1} \le a_{n+1} | X_1 \le a_1, \cdots, X_{n} \le
    a_{n})
    \end{eqnarray*}
    Analogous to the calculation before
    \begin{eqnarray*}
      && P(X_{n+2} \le a_{n+1} | X_2 \le a_1, \cdots, X_{n+1} \le
      a_{n})      \\
      &=& P(Y_{n+3} \le a_{n+1}, \cdots, Y_{n+k+2} \le a_{n+1} | Y_3
      \le b_1, \cdots, Y_{n+k+1} \le b_{n+k-1}) \\
      &=& P(Y_{n+3} \le a_{n+1} | Y_{n+3} \le b_{n+1}) \cdots
      P(Y_{n+k+1} \le a_{n+1} | Y_{n+k+1} \le b_{n+k-1}) \cdot \\
      && P(Y_{n+k+2} \le a_{n+1}) \\
      &=& {F^{1/k}(a_{n+1} \wedge b_{n+1}) \over F^{1/k}(b_{n+1})} \cdots
      {F^{1/k}(a_{n+1} \wedge b_{n+k-1}) \over F^{1/k}(b_{n+k-1})}
      F^{1/k}(a_{n+1}) \\
      &=& P(X_{n+2} \le a_{n+1} | X_2 \le a_1, \cdots, X_{n+1} \le
      a_{n})\\
      \Box
    \end{eqnarray*}


  \item Notice that $M_n=\max(X_1, \cdots, X_n) = \max(Y_2, \cdots,
    Y_{n+k})$. Since $(Y_i)$ is an iid sequence
    \[
    P(M_n \le x) = F^{n+k-1 \over k}(x)
    \]
    Because
    \[
    \lim_{n \to \infty} n \bar{F}(u_n) = \tau
    \]
    by Poisson approximation,
    \begin{eqnarray*}
      \lim_{n \to \infty} F^n(u_n) &=& e^{-\tau} \\
      \lim_{n \to \infty} (F^n)^{\frac{n+k-1}{k} \frac{1}{n}} (u_n) &=&
      \lim_{n \to \infty} (e^{-\tau})^{\frac{n+k-1}{k} \frac{1}{n}} =
      e^{-\tau / k} \\
    \end{eqnarray*}
    That is
    \[
    \lim_{n \to \infty} P(M_n \le u_n) = e^{-\tau / k}
    \]
  \item It is straight-forward to calculate
    \begin{eqnarray*}
      N_n &=& \E \sum_{i=1}^{n-1} I_{\{X_i = X_{i+1}\}} \\
      &=& \sum_{i=1}^{n-1} P(X_i = X_{i+1}) \\
    \end{eqnarray*}
    where
    \begin{eqnarray*}
      && P(X_i = X_{i+1}) \\
      &=& P[Y_{i+1} \ne \max(Y_{i+1}, \cdots,
      Y_{i+k}), Y_{i+k+1} \ne \max(Y_{i+2}, \cdots, Y_{i+k+1})]
    \end{eqnarray*}
    Because $Y_i$ is an iid sequence, the two events of the above
    joint probability are independent. Thus we have
    \begin{eqnarray*}
      P(X_i = X_{i+1}) &=& \left({k-1 \over k}\right)^2
    \end{eqnarray*}
    and
    \begin{eqnarray*}
      N_n &=& (n-1) \left({k-1 \over k}\right)^2 \\
      &\ge& {n-1 \over 4}
    \end{eqnarray*}
    The expected number of equal pairs is at least 1/4 of the number
    of pairs.
  \end{enumerate}

\item
  \begin{enumerate}[(a)]
  \item Proof:

    \begin{eqnarray*}
      e_F(u) &=& \int_{u}^{\infty} {\bar{F}(y) \over \bar{F}(u)} dy
    \end{eqnarray*}
    Let $z = y - u$ and change variable of integration. We get
    \begin{eqnarray*}
      e_F(u) &=& \int_{0}^{\infty} {\bar{F}(z+u) \over \bar{F}(u)} dz
    \end{eqnarray*}
    Due to the assumed property we have
    \begin{eqnarray*}
      \lim_{z \to \infty} {\bar{F}(u+z) \over \bar{F}(u)} &=&
      e^{-\gamma z}
    \end{eqnarray*}
    So
    \begin{eqnarray*}
      \lim_{u \to \infty} e_F(u) = \int_{0}^{\infty} e^{-\gamma z} dz
    \end{eqnarray*}
  \end{enumerate}
\end{enumerate}
\end{document}