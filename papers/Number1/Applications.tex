\subsection{Rank-transformed S\&P 500 Data}

For real financial data, it is unreasonable to expect all
the time series under consideration to have the same tail index. So a
preocedure of standardization has to be adopted. In this section we
use the rank transform.

Suppose we have $p$ time series each of length $n$ and have arranged
them in a $p\times n$ matrix $X_{it}$, where $i = 1, 2, \dots, p$ and
$t=1,2, \dots, n$. For each row of $X$, we transform it as
\begin{eqnarray*}
  R_{it} &=& -\left[
    \log \left({1 \over n+1} \sum_{\tau=1}^n \1_{X_{i\tau} \leq X_{it}} \right)
  \right]^{-1}
\end{eqnarray*}
When $X_{it}$ are iid for each $i$, the argument to the $\log$
function is asymptotically uniformly distributed as $n \to \infty$,
and hence $R_{it}$ is a standard Fr\'echet r.v.

Figure \ref{fig:EigenRatio} shows the ratio of successive eigenvalues
of the matrix $a_{np}^{-2}RR'$, where the rows of matrix $R$ comprise
the rank-transformed sequences of a number of selected time series
in the S\&P 500 index.
\begin{figure}[htb!]
  \centering
  \subfigure[]{
    \includegraphics[scale=0.40]{EigenRatioSP500_100_shown.pdf}
  }
  \subfigure[]{
    \includegraphics[scale=0.40]{EigenRatioSP500_200_shown.pdf}
  }
  \subfigure[]{
    \includegraphics[scale=0.40]{EigenRatioSP500_300_shown.pdf}
  }
  \subfigure[]{
    \includegraphics[scale=0.40]{EigenRatioSP500_400_shown.pdf}
  }
  \caption{$\lambda_{(i+1)} / \lambda_{(i)}$ versus $i$}
  \label{fig:EigenRatio}
\end{figure}
It is seen that, as $i \to \infty$, $\lambda_{(i+1)} / \lambda_{(i)}
\to 1$.
% This is in fact expected based on the theory explained in the
% previous sections. Suppose the sequences are iid and serial
% correlations are absent, i.e. the matrix $M=H H'$ has only one eigen
% value. Then it is clear ${\lambda_{(i+1)} \over
%   \lambda_i}=\left({\Gamma_i \over
%     \Gamma_{i+1}}\right)^{2/\alpha}=\left(1 - {E_{i+1} \over E_1 + E_2
%     + \dots E_{i+1}}\right)^{2/\alpha} \to 1$, where $E_k,
% k=1,2,\dots,i+1$ are iid. exponential rv.
Indeed, as argued in previous sections, $ \lambda_{(i)} \overset{d}{\to}
\Gamma_k^{-2/\alpha} v_{(l)}$.  Now consider $\lambda_{(i+1)}$. One
possibility is $\lambda_{(i+1)} \overset{d}{\to} \Gamma_{k+1}^{-2/\alpha}
v_{(l)}$. In this case
\begin{eqnarray*}
  {\lambda_{(i+1)} \over \lambda_{i}} &\to& \left(
    \Gamma_{i} \over \Gamma_{i+1} \right)^{2/\alpha}
  \overset{d}{=} (U_{1,i})^{2/\alpha} \overset{a.s.}{\longrightarrow}
  1\text{, as }i \to \infty
\end{eqnarray*}
where $U_{a,b}$ denotes the $a$-th upper order statistic in a uniform
sample of size $b$. In words, $\lambda_{(i+1)}$ gets infinitely close to
$\lambda_{(i)}$ in this case. For this reason, any other candidate for
$\lambda_{(i+1)}$ must also be infinitely close to $\lambda_{(i)}$ and
thereby infinitely close to $\Gamma_{k+1}^{-2/\alpha} v_{(l)}$.

So $ \lambda_{(i+1)} \overset{d}{\to} \Gamma_{k+1}^{-2/\alpha}
v_{(l)}$ can be untrue only if $\exists m\exists l'\,(m,l') \neq (1,
l)$ such that $ \lambda_{(i+1)} \overset{d}{\to}
\Gamma_{k+m}^{-2/\alpha} v_{(l')}$ and
\begin{equation}
  \label{eq:X_A}
  \P\left(\left|
    {\Gamma_{k+m}^{-2/\alpha} v_{(l')} \over \Gamma_{k}^{-2/\alpha}
      v_{(l)}} - 1\right| > \epsilon
  \right) \overset{d}{\to} 0 \text{ as } i \to \infty
\end{equation}
Suppose $m > 1$.
\[
\left(
  \Gamma_{k} \over \Gamma_{k+m}
\right)^{2/\alpha} \overset{d}{=} (U_{m,k+m-1})^{2/\alpha}
\]
The variance of $(U_{m,k+m-1})^{2/\alpha}$ remains finite regardless
of $k$ and $m$ (\textcolor{red}{to be proven}), so the convergence in
\eqref{eq:X_A} cannot happen.
