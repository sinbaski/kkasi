\documentclass{article}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage[bookmarks=true]{hyperref}
\usepackage{bookmark}

\input{../physics_common}
\begin{document}
\section{iid sequences}\label{sec:iid}
Consider iid sequences $\{X_{it}\}$, $1 \leq i \leq p$, $1 \leq t \leq
n$. $p$ is fixed while $n \to \infty$. $\pr(X_{it} > x) = p_+ L(x)
x^{-\alpha}$, $\pr(X_{it} < -x) = p_- L(x) x^{-\alpha}$, $\alpha \in
(0,4)$ for a slowly varying function $L(x)$, and $p_+ + p_- = 1$. The
normalizing sequence $a_n$ is such that $\pr(|X_{it}| > a_n) \sim {1
  \over n}$, implying $a_n \sim n^{1/\alpha} l(n)$, where $l(n)$ is a
slowing varying function. Moreover, we assume $\E X_{11} = 0$ if $\E
|X_{11}| < \infty$. The sample covariance matrix is $\mtx
{XX'}$.

For convenience, we let $c$ stand for any constant whose value is not
of importance in the rest of this report. We shall prove
\[
a_n^{-2}\|\mtx {XX'} - \diag(\mtx {XX'})\|_2 \xrightarrow{P} 0
\]

\begin{proof}
  Using the inequality
  \[
  \|\mtx A\|_2 \leq \|\mtx A\|_\infty
  \]
  for an arbitrary matrix $\mtx A$, we have
  \begin{align*}
    \pr(\|\mtx {XX'} - \diag(\mtx {XX'})\|_2 \geq a_n^2 \epsilon) & \leq
    \pr\left(\max_{1\leq i \leq p} \sum_{j=1, j\neq i}^p |\sum_{t=1}^n
    X_{it} X_{jt}| > a_n^2 \epsilon\right) \\
    &\leq \sum_{i=1}^p \sum_{j=1, j\neq i}^p \pr\left(|\sum_{t=1}^n
    X_{1t} X_{2t}| > {a_n^2 \epsilon \over p-1}\right) \\
  \end{align*}
  Thus the large deviation result found in Cline and Hsing
  \cite{ClingHsing1998} and Nagaev \cite{nagaev1979} is
  applicable. With it we obtain
  \begin{align*}
    \pr\left(|\sum_{t=1}^n X_{1t} X_{2t}| > {a_n^2 \epsilon \over p-1}\right)
    &\sim
    c n \pr\left(|X_{11} X_{21}| > {a_n^2 \epsilon \over p-1 }\right)
  \end{align*}
  Now that $|X_{11}|$ and $|X_{21}|$ are iid and regularly varying
  with index $\alpha$, so is $|X_{11} X_{21}|$, according to Jessen
  and Mikosch \cite{JessenMikosch2006}. Thus we have
  \begin{eqnarray*}
    c n \pr\left(|X_{11} X_{21}| > {a_n^2 \epsilon \over p-1 }\right)
    &\sim& c n L_{12}(n) (n^{2/\alpha})^{-\alpha} \to 0\text{,  }n\to\infty
  \end{eqnarray*}
  where $L_{12}$ is a slowly varying function.
\end{proof}
Now, using the result just proved and applying Weyl's perturbation
theorem we obtain
\[
a_n^{-2} \max_{i=1,\dots,p} |\lambda^C_{(i)} -
\lambda^{\text{diag}}_{(i)}| \leq  a_n^{-2}\|C - \diag{C}\| \to 0
\]
Therefore the eigenvalues of $XX'$ can be approximated by those of
$\diag(XX')$:
\begin{eqnarray*}
a_n^{-2}\lambda^{\text{diag}}_{i}  &=& a_n^{-2} \sum_{t=1}^n X_{it}^2
\end{eqnarray*}

\subsection{Upper Order Statistics of the eigenvalues}
When $\alpha \in (0,2)$, $\E X^2 = \infty$. Now that
$\pr(X_{11}^2 > a_n^2) \sim 1/n$, the central limit theorem 
gives, according to Mikosch et al\cite{Embrechts1997} 
\[
a_n^{-2} \sum_{t=1}^n X_{it}^2 \xrightarrow{d} \xi_i \sim S_{\alpha/2}
\]
where $S_{\alpha/2}$ denotes an $\alpha/2$-stable distribution.
Since $(\xi_i)_{i=1}^p$ are iid, the joint density function of the $k$
upper order statistics of $\lambda_i$, the eigenvalues of $a_n^{-2} X X'$
follows as
\begin{eqnarray*}
  f_{\lambda_{(1)}, \dots, \lambda_{(k)}}(x_1, \dots, x_k) &=&
  p(p-1)\cdots(p-k+1) S_{\alpha/2}^{p-k}(x_k) \prod_{i=1}^k
  f_{\alpha/2}(x_i)
\end{eqnarray*}
where $f_{\alpha/2}(x) = {d S_{\alpha/2}(x) \over dx}$.

When $\alpha \in (2,4)$ the central limit theorem gives
\[
a_n^{-2} (\sum_{t=1}^n X_{it}^2 - n \E X^2)\xrightarrow{d}
\xi_i \sim S_{\alpha/2}
\]
Since $a_n \sim n^{1/\alpha} l(n)$, it is clear
\[
a_n^{-2} \sum_{t=1}^n X_{it}^2 \xrightarrow{a.s}\infty
\]

\section{Correlated Sequences}
\subsection{MA(1) process}
First consider the model
\[
X_{it} = Z_{it} + \theta Z_{i,t-1}
\]
We have
\begin{eqnarray*}
  a_n^{-2}(XX')_{ij} &=& a_n^{-2} \sum_{t=1}^n (Z_{it} + \theta
  Z_{i,t-1}) (Z_{jt} + \theta Z_{j,t-1}) \\
  &=& a_n^{-2} \sum_{t=1}^n Z_{it} Z_{jt} + a_n^{-2} \theta \sum_{t=1}^n
  Z_{it} Z_{j,t-1} \\
  && +\theta a_n^{-2} \sum_{t=1}^n Z_{i, t-1}
  Z_{j,t} + \theta^2 a_n^{-2} \sum_{t=1}^n Z_{i,t-1} Z_{j,t-1}
\end{eqnarray*}
Consider $\pr(a_n^{-2} \sum_{t=1}^n Z_{1t} Z_{2t} > \epsilon)$,
$\forall \epsilon>0$. Since $Z_1 Z_2 \in \mathcal R_{-\alpha}$ (See
Mikosch and Jessen \cite{JessenMikosch2006}) and $\E Z_1 Z_2 = 0$ if
$\E|Z_1Z_2| < \infty$. By the large deviation result of Cline and
Hsing \cite{ClingHsing1998} and Nagaev \cite{nagaev1979}
\begin{eqnarray*}
  && \pr(a_n^{-2} \sum_{t=1}^n Z_{1t} Z_{2t} > \epsilon)  \\
  &\sim& c n \pr(|Z_1 Z_2| > a_n^{2} \epsilon)  \\
\end{eqnarray*}
Because $a_n \sim n^{1/\alpha} l(n)$, we have
\begin{eqnarray*}
  \pr(|Z_1 Z_2| > a_n^{2} \epsilon) &\sim& n^{-2} L_{12}(n)
\end{eqnarray*}
where $L_{12}(n)$ is a slowly varying function. Thus
\[
\pr(a_n^{-2} \sum_{t=1}^n Z_{1t} Z_{2t} > \epsilon) \to 0
\]

On the other hand $Z^2 \in \mathcal R_{-\alpha/2}$, hence
\begin{eqnarray*}
  \pr(a_n^{-2} \sum_{t=1}^n Z_{1t}^2 > \epsilon) &\sim& c n
  \pr(Z_{1t}^2 > a_n^2 \epsilon) \\
  &\sim& c n \pr(|Z_{1t}| > a_n) \\
  &\sim& c L(n)
\end{eqnarray*}
Therefore
\begin{eqnarray*}
  \pr(a_n^{-2} \sum_{t=1}^n Z_{it} Z_{jt}\I{i \neq j} > \epsilon) \to
  0 \\
  \pr(a_n^{-2} \sum_{t=1}^n Z_{i,t-1} Z_{j,t-1} \I{i \neq j} >
  \epsilon) \to 0 \\
  \pr(a_n^{-2} \sum_{t=1}^n Z_{it} Z_{j,t-1} > \epsilon) \to 0
  \\
  \pr(a_n^{-2} \sum_{t=1}^n Z_{i, t-1} Z_{j,t} > \epsilon) \to 0
\end{eqnarray*}
Then it follows, for $i \neq j$, i.e. non-diagonal entries,
$\pr(a_n^{-2} (XX')_{ij} > \epsilon) \to 0$; and for diagonal entries
\begin{eqnarray*}
  && \pr\left[(XX')_{ii} - (1 + \theta^2)\sum_{t=1}^n
      Z_{it}^2 > a_n^{2} \epsilon \right] \\
  &=& \pr\left[\theta^2 ( Z_{0}^2-Z_{n}^2) > a_n^{2} \epsilon
  \right] \to 0\\
\end{eqnarray*}
So for the eigenvalues of $a_n^{-2}XX'$, $\lambda_{(1)} > \lambda_{(2)} >
\dots > \lambda_{(p)}$, we have
\[
(\lambda_{(1)}, \lambda_{(2)}, \dots, \lambda_{(p)}) \xrightarrow{P}
(1+\theta^2)(\sum_{t=1}^n Z_{1t}^2, \sum_{t=1}^n Z_{2t}^2, \dots,
\sum_{t=1}^n Z_{pt}^2)
\]
As argued in the iid case in \S\ref{sec:iid}, if $\alpha \in (0,2)$,
$\sum_{t=1}^n Z_{it}^2 \xrightarrow{d} \xi_{i}$, where $\xi_{i}$ is an
$\alpha/2$-stable rv; if $\alpha \in (2,4)$, $\sum_{t=1}^n Z_{it}^2
\xrightarrow{a.s.} \infty$.

\subsection{Cross-correlation limited to order 1}\label{sec:B1}
Now we consider the model
\[
X_{it} = Z_{it} + \varphi Z_{i-1,t}
\]
\begin{eqnarray*}
  (XX')_{ij} &=& \sum_{t=1}^n (Z_{it} + \varphi Z_{i-1,t})(Z_{jt} +
  \varphi Z_{j-1,t}) \\
  &=& \sum_{t=1}^n (Z_{it}^2 + \varphi^2 Z_{i-1,t}^2)\I{i=j}
  + \sum_{t=1}^n (Z_{it}Z_{jt}+\varphi^2 Z_{i-1,t}Z_{j-1,t})\I{i\neq j}
  \\
  && + \varphi \sum_{t=1}^n Z_{it}^2 \I{i=j-1} 
  +\varphi\sum_{t=1}^n Z_{it} Z_{j-1,t}\I{i\neq j-1} \\
  && + \varphi \sum_{t=1}^n Z_{i-1,t}^2 \I{i=j+1} 
  +\varphi\sum_{t=1}^n Z_{jt} Z_{i-1,t}\I{i\neq j+1} \\
\end{eqnarray*}
As shown in previous sections, $\pr(a_n^{-2} \sum_{t=1}^n Z_{1t}Z_{2t} >
\epsilon) \to 0$, as $n \to \infty$. Therefore
\[
\pr\left(
  (XX')_{ij} - A_{ij}> a_n^2 \epsilon \right) \to 0\text{,  }n \to 0
\]
where
\[
A_{ij} = \sum_{t=1}^n (Z_{it}^2 + \varphi^2 Z_{i-1,t}^2)\I{i=j}
      + \varphi \sum_{t=1}^n Z_{it}^2 \I{i=j-1} 
      + \varphi \sum_{t=1}^n Z_{i-1,t}^2 \I{i=j+1}
\]
If $\alpha \in (0,2)$, $a_n^{-2}\sum_{t=1}^n Z_{it}^2 \xrightarrow{d}
\xi_i \sim S_{\alpha/2}$. So we have in this case
\[
A =
\begin{pmatrix}
  \xi_1 + \varphi^2 \xi_0 & \varphi \xi_1 & 0 & \cdots & 0 \\
  \varphi \xi_1 & \xi_2 + \varphi^2 \xi_1 & \varphi \xi_2 & \cdots & 0 \\
  0 & \varphi \xi_2 & \xi_3 + \varphi^2 \xi_2 & \cdots & 0 \\
  \vdots & \vdots & \vdots & \ddots & \vdots \\
  0 & 0 & 0 & \cdots & \xi_p + \varphi^2 \xi_{p-1}
\end{pmatrix}
\]

\subsection{cross- \& auto-correlation limited to order 1}
Here we consider the mode
\[
X_{it} = Z_{it} + \theta Z_{i, t-1} + \varphi Z_{i-1, t}
\]
The calculations are similar to those in \S\ref{sec:B1}. For clearity
we write $A_{ij} \sim B_{ij}$ if $\pr(|A_{ij} - B_{ij}| > a_n^2 \epsilon)
\to 0$, $\forall \epsilon > 0$ and $n \to \infty$. Then we have
\begin{eqnarray*}
  (XX')_{ij} &\sim& \left[
    \sum_{t=1}^n Z_{it}^2 + \theta^2 \sum_{t=1}^n Z_{i,t-1}^2 +
    \varphi^2 \sum_{t=1}^n Z_{i-1,t}^2 
  \right]\I{i=j} \\
  && + \varphi \left[
    \sum_{t=1}^n Z_{it}^2 \I{i=j-1} + \sum_{t=1}^n Z_{i-1, t}^2 \I{i=j+1}
  \right]
\end{eqnarray*}
When $\alpha \in (0,2)$, the matrix $A$ comprising the entries on the
right-hand-side of the above expression is
\[
A =
\begin{pmatrix}
  (1 + \theta^2)\xi_1 + \varphi^2 \xi_0 & \varphi \xi_1 & 0 & \cdots & 0 \\
  \varphi \xi_1 & (1 + \theta^2)\xi_2 + \varphi^2 \xi_1 & \varphi \xi_2 & \cdots & 0 \\
  0 & \varphi \xi_2 & (1 + \theta^2)\xi_3 + \varphi^2 \xi_2 & \cdots & 0 \\
  \vdots & \vdots & \vdots & \ddots & \vdots \\
  0 & 0 & 0 & \cdots & (1 + \theta^2)\xi_p + \varphi^2 \xi_{p-1}
\end{pmatrix}
\]
where each $\xi_i \sim S_{\alpha/2}$.

\subsection{A more general model}
Now we consider the model
\begin{eqnarray*}
  X_{it} &=& \sum_{k=0}^\infty \sum_{l=0}^\infty h_{kl} Z_{i-k,t-l}
\end{eqnarray*}
\subsubsection[alpha in (0,2)]{$\alpha \in (0,2)$}
In this case we have
\begin{eqnarray*}
  (XX')_{ij} &=& \sum_{t=1}^n \sum_{k=0}^\infty \sum_{k'=0}^\infty
  \sum_{l=0}^\infty \sum_{l'=0}^\infty h_{kl} h_{k'l'} Z_{i-k,t-l}
  Z_{j-k',t-l'} \\
  &=& \sum_{t=1}^n \sum_{k=0}^\infty \sum_{l=0}^\infty h_{kl}
  h_{j-i+k,l} Z_{i-k, t-l}^2 \\
  && + \sum_{t=1}^n \sum_{k=0}^\infty \sum_{i-k \neq j-k'}^\infty
  \sum_{l,l'=0}^\infty h_{kl} h_{k'l'} Z_{i-k,t-l} Z_{j-k',t-l'} \\
  && + \sum_{t=1}^n \sum_{k=0}^\infty \sum_{l\neq l'} h_{kl}
  h_{j-i+k, l'} Z_{i-k,t-l} Z_{i-k,t-l'} \\
  &=& I^{(1)}_{ij} + I^{(2)}_{ij} + I^{(3)}_{ij}
\end{eqnarray*}
\begin{eqnarray*}
  && \pr(\left| I^{(2)}_{ij} \right| > a_n^2 \epsilon) \\
  &\leq& \pr\left(
    \sum_{k=0}^\infty \sum_{i-k \neq j-k'}^\infty
    \sum_{l,l'=0}^\infty | h_{kl} h_{k'l'}| \left|
      \sum_{t=1}^n  Z_{i-k,t-l} Z_{j-k',t-l'} \right| > a_n^2 \epsilon
  \right) \\
  &=& \pr\left(
    \sum_{k=0}^\infty \sum_{i-k \neq j-k'}^\infty
    \sum_{l,l'=0}^\infty | h_{kl} h_{k'l'}| \left|
      \sum_{t=1}^n  Z_{i-k,t-l} Z_{j-k',t-l'} \right|
    \I{A_{kk'll'}} > a_n^2 \epsilon
  \right) \\
  && + \pr\left(
    \sum_{k=0}^\infty \sum_{i-k \neq j-k'}^\infty
    \sum_{l,l'=0}^\infty | h_{kl} h_{k'l'}| \left|
      \sum_{t=1}^n  Z_{i-k,t-l} Z_{j-k',t-l'} \right|
    \I{A^c_{kk'll'}} > a_n^2 \epsilon
  \right) \\
  &=& P^{(2)}_1 + P^{(2)}_2
\end{eqnarray*}
where the events $A_{kk'll'}$ are
\begin{eqnarray*}
  A_{kk'll'} &=& \left\{
  k,k',l,l': | h_{kl} h_{k'l'}| \left| \sum_{t=1}^n  Z_{i-k,t-l} Z_{j-k',t-l'}
  \right| > a_n^2 \epsilon
  \right\}
\end{eqnarray*}
Then we have
\begin{eqnarray*}
  P^{(2)}_1 &\leq& \pr\left(
    \bigcup_{\substack{k \geq 0 \\ i-k \neq j-k' \\ l,l'\geq0}}
    A_{kk'll'}
  \right) \\
  &\leq& \sum_{k=0}^\infty \sum_{i-k \neq j-k'}^\infty
  \sum_{l,l'=0}^\infty \pr\left(
    \left| \sum_{t=1}^n  Z_{i-k,t-l} Z_{j-k',t-l'}
    \right| > | h_{kl} h_{k'l'}|^{-1} a_n^2 \epsilon 
  \right)
\end{eqnarray*}
Note $\E Z_1 Z_2 = (\E Z_1)^2 = 0$ if $\E|Z_1| < \infty$. Thus the
large deviation results of Cline and Hsing \cite{ClingHsing1998} and
Nagaev \cite{nagaev1979} give
\begin{eqnarray*}
  && \pr\left(
    \left| \sum_{t=1}^n  Z_{i-k,t-l} Z_{j-k',t-l'}
    \right| > | h_{kl} h_{k'l'}|^{-1} a_n^2 \epsilon 
  \right) \\
  &\sim& c n \pr(|Z_1 Z_2| > | h_{kl} h_{k'l'}|^{-1} a_n^2 \epsilon) \\
  &\sim& c n | h_{kl} h_{k'l'}|^{\alpha} a_n^{-2\alpha}
\end{eqnarray*}
\begin{eqnarray*}
  P^{(2)}_1 &\leq& c \left( \sum_{k=0}^\infty \sum_{i-k \neq j-k'}^\infty
  \sum_{l,l'=0}^\infty | h_{kl} h_{k'l'}|^{\alpha} \right) l(n) n^{-1}
\to 0
\end{eqnarray*}
As for $P^{(2)}_2$ we first apply Markov's inequality
\begin{eqnarray*}
  P^{(2)}_2 &\leq& a_n^{-2} \epsilon^{-1}
  \sum_{k=0}^\infty \sum_{i-k \neq j-k'}^\infty
  \sum_{l,l'=0}^\infty | h_{kl} h_{k'l'}| \E \left|
  \sum_{t=1}^n  Z_{i-k,t-l} Z_{j-k',t-l'} \right|
  \I{A^c_{kk'll'}}
\end{eqnarray*}
Since the large deviation results imply $\pr(\sum_{t=1}^n  Z_{i-k,t-l}
Z_{j-k',t-l'} > x) \sim n \pr(|Z_1 Z_2| > x)$, we have
\begin{eqnarray*}
  && | h_{kl} h_{k'l'}| \E \left| \sum_{t=1}^n  Z_{i-k,t-l} Z_{j-k',t-l'} \right|
  \I{A^c_{kk'll'}} \\
  &\leq& \left(
    | h_{kl} h_{k'l'}|^{\alpha + \delta} \E \left| \sum_{t=1}^n
      Z_{i-k,t-l} Z_{j-k',t-l'} \right|^{\alpha + \delta}
    \I{A^c_{kk'll'}} \right)^{1/(\alpha + \delta)} \\
    &\sim& \left[
      {\alpha \over \delta} \pr\left(
      | h_{kl} h_{k'l'}| \left| \sum_{t=1}^n  Z_{i-k,t-l} Z_{j-k',t-l'}
      \right| > a_n^2 \epsilon \right) \right]^{1/(\alpha + \delta)} \\
  &\sim& \left[
    {\alpha \over \delta} | h_{kl} h_{k'l'}|^{\alpha}
    c n a_n^{-2\alpha} L_{12}(a_n)
    \right]^{1/(\alpha + \delta)}
\end{eqnarray*}
where $\delta$ is some constant such that $\delta > \max\{1-\alpha,
0\}$. Therefore
\begin{eqnarray*}
  P^{(2)}_2 &\leq& c  \left[\sum_{k=0}^\infty \sum_{i-k \neq j-k'}^\infty
  \sum_{l,l'=0}^\infty |h_{kl} h_{k'l'}|^{\alpha/(\alpha + \delta)}\right]
  n^{1/(\alpha + \delta)} a_n^{-2\alpha/(\alpha + \delta )-2} L_{12}(a_n)\\
  &\to&  0
\end{eqnarray*}
Next we show
\begin{eqnarray*}
  \pr(|I^{(3)}_{ij}| > a_n^2 \epsilon) &\to& 0
\end{eqnarray*}
\begin{eqnarray*}
  && \pr(|I^{(3)}_{ij}| > a_n^2 \epsilon) \\
  &\leq& \pr(\sum_{t=1}^n \sum_{\substack{l,l'=0 \\ l \neq l'}}^\infty
  \left|\sum_{k=0}^\infty h_{kl}h_{j-i+k,l'} Z_{i-k,t-l}Z_{i-k,t-l'}\right|
  \I{A_{tll'}} > a_n^2 \epsilon ) \\
  && + \pr(\sum_{t=1}^n \sum_{\substack{l,l'=0 \\ l \neq l'}}^\infty
  \left|\sum_{k=0}^\infty h_{kl}h_{j-i+k,l'} Z_{i-k,t-l}Z_{i-k,t-l'}\right|
  \I{A^c_{tll'}} > a_n^2 \epsilon ) \\
  &=& P^{(3)}_1 + P^{(3)}_2
\end{eqnarray*}
where the events $A_{tll'}$ are
\begin{eqnarray*}
  A_{tll'} &=& \left\{t,l,l': \left|
      \sum_{k=0}^\infty h_{kl}h_{j-i+k,l'} Z_{i-k,t-l}Z_{i-k,t-l'}
    \right| > a_n^2 \epsilon \right\}
\end{eqnarray*}
\begin{eqnarray*}
  P^{(3)}_1 &\leq& n \sum_{\substack{l,l'=0 \\ l \neq l'}}^\infty \pr\left(
    \left|\sum_{k=0}^\infty h_{kl}h_{j-i+k,l'} Z_{i-k,t-l}Z_{i-k,t-l'}\right| > a_n^2 \epsilon
  \right) \\
  &\sim& n \sum_{\substack{l,l'=0 \\ l \neq l'}}^\infty \sum_{k=0}^\infty |h_{kl}h_{j-i+k,l'}|^{\alpha} \pr(|Z_1 Z_2| > a_n^2 \epsilon)
  \\
  &\sim& c n \sum_{\substack{l,l'=0 \\ l \neq l'}}^\infty
  \sum_{k=0}^\infty |h_{kl}h_{j-i+k,l'}|^{\alpha} a_n^{-2\alpha} L_{12}(a_n)\\  
  &\sim& c n^{-1} l(n)  \to 0
\end{eqnarray*}
where $L_{12}(\cdot)$ and $l(\cdot)$ are slowly varying functions. As
for $P^{(3)}_2$, Markov's inequality gives
\begin{eqnarray*}
  P^{(3)}_2 &\leq& c n a_n^{-2} \sum_{\substack{l,l'=0 \\ l \neq l'}}^\infty
  \E\left|\sum_{k=0}^\infty h_{kl}h_{j-i+k,l'}
    Z_{i-k,l}Z_{i-k,l'}\right| \I{A^c_{tll'}} \\
\end{eqnarray*}
Let
\begin{eqnarray*}
  Y_{tll'} &=& \left|\sum_{k=0}^\infty h_{kl}h_{j-i+k,l'}
              Z_{i-k,t-l}Z_{i-k,t-l'}\right|
\end{eqnarray*}
\begin{enumerate}[i)]
\item In case $\alpha < 1$. Karamata's theorem yields
  \begin{eqnarray*}
    && \E Y_{tll'}\I{A^c_{tll'}} \\
    &\sim& {\alpha \over 1 -\alpha} \pr(Y_{tll'} > a_n^2 \epsilon) \\
    &\sim& c \sum_{k=0}^\infty |h_{kl}h_{j-i+k,l'}|^{\alpha}
           a_n^{-2\alpha} L_{12}(a_n) \\
  \end{eqnarray*}
  Thus
  \begin{eqnarray*}
    P^{(3)}_2 &\leq& c n^{-2(1/\alpha + 1)+1}l(n) \to 0
  \end{eqnarray*}

\item In case $\alpha > 1$. 
  \begin{eqnarray*}
    && \E Y_{tll'} \I{A^c_{tll'}} \leq \E Y_{tll'} = \text{constant}
  \end{eqnarray*}
  \begin{eqnarray*}
    P^{(3)}_2 &\leq& cna_n^{-2} \sim c n^{1-2/\alpha} l(n) \to 0
  \end{eqnarray*}
\item In case $\alpha=1$.
  Choose $M$ so large that $\pr(Y_{tll'} > x) \leq {L(x) \over x}
  (1 + \epsilon)$ for a slowly varying function $L(x)$
  where $x > M$. Then we have
  \begin{eqnarray*}
    && \E Y_{tll'} \I{A^c_{tll'}} \\
    &\leq& \text{constant} + \int_{M}^{a_n^2 \epsilon}
           {L(x) \over x} dx
  \end{eqnarray*}
  According to Mikosch et al \cite{Embrechts1997},
  \begin{eqnarray*}
    \int_{M}^{a_n^2 \epsilon}
    {L(x) \over x} dx &=& L_1{a_n^2}
  \end{eqnarray*}
  where $L_1(\cdot)$ is a slowly varying function. So we have
  \begin{eqnarray*}
    P^{(3)}_2 &\leq& c n a_n^{-2} L_1(a_n)\\
    &\sim& c n^{-2/\alpha + 1} l(n) \to 0
  \end{eqnarray*}
\end{enumerate}
Now we have shown $I^{(2)}_{ij}, I^{(3)}_{ij} \xrightarrow{P} 0$ as $n
\to \infty$. Then it is clear $(XX')_{ij}$ has the following structure
as $n \to \infty$:
\begin{eqnarray*}
  (XX')_{ij} &=& \sum_{t=1}^n \sum_{k=0}^\infty \sum_{l=0}^\infty
  h_{kl} h_{k+j-i,l} Z_{i-k, t-l}^2
\end{eqnarray*}
When $j < i$, one may re-write
\begin{eqnarray*}
  (XX')_{ij} &=& \sum_{t=1}^n \sum_{k=j-i}^\infty \sum_{l=0}^\infty
  h_{k+|j-i|,l} h_{kl} Z_{j-k, t-l}^2
\end{eqnarray*}
Because $h_{kl} = 0$ if $\min\{k,l\} < 0$ we have
\begin{eqnarray*}
  (XX')_{ij} &=& \sum_{t=1}^n \sum_{k=0}^\infty \sum_{l=0}^\infty
  h_{k+|j-i|,l} h_{kl} Z_{j-k, t-l}^2
\end{eqnarray*}
In summary
\begin{eqnarray*}
  (XX')_{ij} &=& \sum_{t=1}^n \sum_{k=0}^\infty \sum_{l=0}^\infty
  h_{k+|j-i|,l} h_{kl} Z_{i \wedge j -k, t-l}^2
\end{eqnarray*}

\subsection{When the matrix dimension tends to infinity}
Consider the 1-norm
\begin{eqnarray*}
  && \| a_n^{-2} XX' - a_n^{-2} \sum_{t=1}^n
     \sum_{k=0}^\infty \sum_{l=0}^\infty
     h_{k+|j-i|,l} h_{kl} Z_{i \wedge j -k, t-l}^2\|_1 \\
  &=& a_n^{-2} \sum_{i=1}^p (I^{(2)}_{ii} + I^{(3)}_{ii})
\end{eqnarray*}

\bibliographystyle{unsrt}
\bibliography{../thesis/econophysics}
\end{document}
