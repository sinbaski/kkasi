\documentclass{article}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage[bookmarks=true]{hyperref}
\usepackage{bookmark}

\input{../physics_common}
\begin{document}
\section{iid sequences}\label{sec:iid}
Consider iid sequences $\{X_{it}\}$, $1 \leq i \leq p$, $1 \leq t \leq
n$. $p$ is fixed while $n \to \infty$. $\pr(X_{it} > x) = p_+ L(x)
x^{-\alpha}$, $\pr(X_{it} < -x) = p_- L(x) x^{-\alpha}$ for a slowly
varying function $L(x)$, and $p_+ + p_- = 1$. The normalizing sequence
$a_n$ is such that $\pr(|x_{it}| > a_n) \sim {1 \over n}$, implying
$a_n \sim n^{1/\alpha} l(n)$, where $l(n)$ is a slowing varying
function. Moreover, we assume $\E X_{11} = 0$ if $\E X_{11} <
\infty$. The sample covariance matrix is $\mtx {XX'}$.

For convenience, we let $c$ stand for any constant whose value is not
of importance in the rest of this report. We shall prove
\[
a_n^{-2}\|\mtx {XX'} - \diag(\mtx {XX'})\|_2 \xrightarrow{P} 0
\]

\begin{proof}
  Using the inequality
  \[
  \|\mtx A\|_2 \leq \|\mtx A\|_\infty
  \]
  for an arbitrary matrix $\mtx A$, we have
  \begin{align*}
    \pr(\|\mtx {XX'} - \diag(\mtx {XX'})\|_2 \geq a_n^2 \epsilon) & \leq
    \pr\left(\max_{1\leq i \leq p} \sum_{j=1, j\neq i}^p |\sum_{t=1}^n
    X_{it} X_{jt}| > a_n^2 \epsilon\right) \\
    &\leq \sum_{i=1}^p \sum_{j=1, j\neq i}^p \pr\left(|\sum_{t=1}^n
    X_{1t} X_{2t}| > {a_n^2 \epsilon \over p-1}\right) \\
  \end{align*}
  Since $\E X_{1t} X_{2t} = (\E X_{11})^2$, which is either 0 or
  $\infty$, the large deviation result found in Cline and Hsing
  \cite{ClingHsing1998} and Nagaev \cite{nagaev1979} is
  applicable. With it we obtain
  \begin{align*}
    \pr\left(|\sum_{t=1}^n X_{1t} X_{2t}| > {a_n^2 \epsilon \over p-1}\right) &\sim
    c n \pr\left(|X_{11} X_{21}| > {a_n^2 \epsilon \over p-1 }\right)
  \end{align*}
  Now that $|X_{11}|$ and $|X_{21}|$ are iid and regularly varying
  with index $\alpha$, so is $|X_{11} X_{21}|$, according to Jessen
  and Mikosch \cite{JessenMikosch2006}. Thus we have
  \[
  c n \pr\left(|X_{11} X_{21}| > {a_n^2 \epsilon \over p-1 }\right)
  \to 0
  \]
\end{proof}
Now, using the result just proved and applying Weyl's perturbation
theorem we obtain
\[
a_n^{-2} \max_{i=1,\dots,p} |\lambda^C_{(i)} -
\lambda^{\text{diag}}_{(i)}| \leq  a_n^{-2}\|C - \diag{C}\| \to 0
\]
Therefore the eigenvalues of $C$ can be approximated by those of
$\diag(C)$:
\begin{eqnarray*}
a_n^{-2}\lambda^{\text{diag}}_{i}  &=& a_n^{-2} \sum_{t=1}^n X_{it}^2
\end{eqnarray*}

\subsection{Upper Order Statistics of the eigenvalues}
Because $\pr(X_{11}^2 > a_n^2) \sim 1/n$, the central limit theorem
gives, according to Mikosch et al\cite{Embrechts1997},
\[
a_n^{-2} \sum_{t=1}^n X_{it}^2 \xrightarrow{d} \xi_i \sim S_{\alpha/2}
\]
where $S_{\alpha/2}$ denotes an $\alpha/2$-stable distribution. Since
$(\xi_i)_{i=1}^p$ are iid, the joint density function of the $k$ upper
order statistics of $\lambda_i$, the eigenvalues of $a_n^{-2} X X'$
follows as
\begin{eqnarray*}
  f_{\lambda_{(1)}, \dots, \lambda_{(k)}}(x_1, \dots, x_k) &=&
  p(p-1)\cdots(p-k+1) S_{\alpha/2}^{p-k}(x_k) \prod_{i=1}^k
  f_{\alpha/2}(x_i)
\end{eqnarray*}
where $f_{\alpha/2}(x) = {d S_{\alpha/2}(x) \over dx}$.

\section{Correlated Sequences}
Now we consider the situation where the sequences $X_{it}$ is
constructed as
\[
X_{it} = \sum_{k=0}^{\infty} \sum_{l=0}^{\infty} h_{kl} Z_{i-k, t-l}
\]
where $Z_{a,b}$ are iid and $a,b \in \mathbb{Z}$ while $i=1,\dots,p$,
$t=1,\dots,n$ with $p$ fixed and $n \to \infty$. $Z_{a,b}$ has
regularly varying tails as specified in \S\ref{sec:iid}.
Define matrix $\mtx M = \mtx {H H'}$ and matrix $\mtx M^{(m)}_q$ with
elements
\[
M^{(m)}_{q; i,j} = \left\{
  \begin{array}{ll}
    M_{i-q, j-q} & \text{if } i,j = q, q+1, \dots, q+m \\
    0 & \text{otherwise}
  \end{array}
\right.
i,j = 1,2,\dots,p
\]
In addition define $\mtx X^{(m)}$ to have elements
\[
X^{(m)}_{ij} = \sum_{k=0}^{m} \sum_{l=0}^{\infty} h_{kl} Z_{i-k, t-l}
\]
and
\[
D_i = \sum_{j=1}^p Z_{ij}^2
\]
Following the arguments of Davis, Mikosch and
Pfaffel\cite{Mikosch2014} and replacing $a_{np}$ with $a_n$, it can be
proven
\begin{enumerate}[i)]
\item if $\alpha \in (0, 1]$ and $\E|Z| = \infty$ or if $\alpha \in
  [1, 2)$, $\E|Z| < \infty$ and $\E Z = 0$.
  \[
  \lim_{m\to \infty} \limsup_{n\to\infty} \pr\left(
    \|\mtx{X X'} - \mtx X^{(m)} \mtx X'^{(m)}\|_2 \geq a_n^2 \epsilon
  \right) = 0 \text{, } \forall \epsilon > 0  
  \]
\item if $\alpha \in [2, 4)$ and $\E Z = 0$
  \begin{align*}
    & \lim_{m\to \infty} \limsup_{n\to\infty} \pr\left(
      \|(\mtx{XX'} - \E\mtx {XX'}) - (\mtx{X^{(m)} X'^{(m)}} - \E
      \mtx{X^{(m)} X'^{(m)}})\|_2 \geq a_n^2 \epsilon \right) \\
    &= 0 \text{, } \forall \epsilon > 0
  \end{align*}
\end{enumerate}

% \subsection[Approximating XX' when alpha in (0,2)]{Approximating $XX'$
%   when $\alpha \in (0,2)$}
% \begin{eqnarray*}
%   \|XX' - X^{(m)}(X^{(m)})'\|_2 &\leq& \|XX' -
%   X^{(m)}(X^{(m)})'\|_\infty \\
%   &=& \max_{i = 1,\dots,p} \sum_{j=1}^p \left|
%     \sum_{t=1}^n \sum_{k \vee k' > m} \sum_{l,l'=0}^\infty
%     h_{k,l}h_{k',l'} Z_{i-k, t-l} Z_{j-k', t-l'} \right| \\
%   &=& \max_{i = 1,\dots,p} \sum_{j=1}^p \left|
%     \sum_{t=1}^n \sum_{k \vee (k+j-i) > m} \sum_{l=0}^\infty
%     h_{k,l}h_{j-i+k,l} Z_{i-k, t-l}^2 \right| \\
%   && + \max_{i = 1,\dots,p} \sum_{j=1}^p \left|
%     \sum_{t=1}^n \sum_{k \vee k'>m} \sum_{l \neq l'}
%     h_{k,l} h_{k',l'} Z_{i-k, t-l} Z_{j-k',t-l} \right| \\
%   && + \max_{i = 1,\dots,p} \sum_{j=1}^p \left|
%     \sum_{t=1}^n \sum_{\substack{k \vee k'>m \\i-k \neq j-k'}}
%     \sum_{l=0}^\infty h_{k,l}h_{k',l'} Z_{i-k, t-l} Z_{j-k',t-l}
%   \right| \\
%   &=& I_n^{(1)} + I_n^{(2)} + I_n^{(3)}
% \end{eqnarray*}

\subsection[Approximation by DM when alpha in (0,2)]{Approximating
  $X^{(m)}(X^{(m)})'$ when $\alpha \in (0, 2)$}
We have in this case
\[
a_n^{-2} \|\mtx X^{(m)} (\mtx X^{(m)})' - \sum_{q=-m}^p D_q \mtx M_q^{(m)}\|_2
\xrightarrow{P} 0
\]
\begin{proof}
  The $(i,j)$-th element of $\mtx{X^{(m)} X'^{(m)}}$ is
  \begin{eqnarray*}
    (\mtx{X^{(m)} X'^{(m)}})_{ij} &=&
    \sum_{t=1}^n \sum_{k=0}^m \sum_{l=0}^\infty \sum_{k'=0}^m
    \sum_{l'=0}^\infty h_{kl} h_{k'l'} Z_{i-k, t-l} Z_{j-k', t-l'} \\
    &=& \sum_{t=1}^n \sum_{k=0}^m \sum_{l=0}^\infty h_{kl}h_{j-i+k,l}
    Z_{i-k, t-l}^2 \\
    && + \sum_{t=1}^n \sum_{k, k'=0}^m \sum_{\substack{l,l'=0\\l\neq l'}}^\infty
    h_{kl} h_{k'l'} Z_{i-k, t-l} Z_{j-k', t-l'} \\
    && + \sum_{t=1}^n \sum_{\substack{k,k'=0\\ i-k \neq j-k'}}^m \sum_{l=0}^{\infty}
    h_{kl} h_{k'l'} Z_{i-k, t-l} Z_{j-k', t-l} \\
    &=& I^{(1)}_{ij} + I^{(2)}_{ij} + I^{(3)}_{ij}
  \end{eqnarray*}
  Next we prove
  \begin{eqnarray*}
    \pr\left(
      a_n^{-2} \|\mtx I^{(1)} - \sum_{q=-m}^p D_q \mtx M_{q}^{(m)}\|_2 > \epsilon
    \right) \to 0 \text{, as } n \to 0
  \end{eqnarray*}
  From $\|\cdot\|_2 \leq \|\cdot\|_\infty$ it follows
  \begin{eqnarray*}
    && \pr\left(
      a_n^{-2} \|\mtx I^{(1)} - \sum_{q=-m}^p D_q \mtx M_{q}^{(m)}\|_2 > \epsilon
    \right) \\
    &\leq& \sum_{i=1}^p \sum_{j=1}^p \pr\left(
      \left| I^{(1)}_{ij} - \sum_{q=-m}^p D_q M_{q; ij}^{(m)} \right| > a_n^2
      \epsilon \right)
  \end{eqnarray*}
  Observe
  \begin{eqnarray*}
    && I^{(1)}_{ij} - \sum_{q=-m}^p D_q M_{q; ij}^{(m)} \\
    &=& \sum_{t=1}^n \sum_{k=0}^m \sum_{l=0}^\infty h_{kl}h_{j-i+k,l}
    Z_{i-k, t-l}^2 - \sum_{k=i-p}^{i+m} D_{i-k} M_{i-k; ij}^{(m)}
  \end{eqnarray*}
  Note that $M_{i-k; ij}^{(m)}$ is non-zero only if $i-k \leq i \leq
  i-k+m$, that is, if $0 \leq k \leq m$. Hence we can write
  \begin{eqnarray*}
    && \sum_{t=1}^n \sum_{k=0}^m \sum_{l=0}^\infty h_{kl}h_{j-i+k,l}
    Z_{i-k, t-l}^2 - \sum_{k=i-p}^{i+m} D_{i-k} M_{i-k; ij}^{(m)} \\
    &=& \sum_{t=1}^n \sum_{k=0}^m \left(
      \sum_{l=0}^\infty h_{kl}h_{j-i+k,l} Z_{i-k, t-l}^2 - Z_{i-k, t}^2 M_{k,
        j-i+k} \right) \\
    &=& \sum_{t=1}^n \sum_{k=0}^m \left(
      \sum_{l=0}^\infty h_{kl}h_{j-i+k,l} Z_{i-k, t-l}^2 - \sum_{l=0}^{\infty}
      h_{kl} h_{j-i+k, l} Z_{i-k, t}^2  \right) \\
    &=& \sum_{k=0}^m \sum_{l=0}^\infty h_{kl} h_{j-i+k, l}\left(
      \sum_{t=1}^l Z_{i-k, t-l}^2 - \sum_{t=n-l+1}^n Z_{i-k, t}^2
    \right)
  \end{eqnarray*}
  Next we prove $\pr\left[\sum_{k=0}^m \sum_{l=0}^\infty h_{kl} h_{j-i+k, l}
    \sum_{t=1}^l Z_{i-k, t-l}^2 > a_n^2 \epsilon \right] \to 0$ as
  $n \to \infty$.
  \begin{eqnarray*}
    && \pr\left[\sum_{k=0}^m \sum_{l=0}^\infty h_{kl} h_{j-i+k, l}
      \sum_{t=1}^l Z_{i-k, t-l}^2 > a_n^2 \epsilon \right] \\
    &\leq& \pr\left[\sum_{k=0}^m \sum_{l=0}^\infty | h_{kl} h_{j-i+k,
        l} | \sum_{t=1}^l Z_{i-k, t-l}^2 > a_n^2 \epsilon \right] \\
    &\leq& \pr\left[c \sum_{k=0}^m \sum_{l=0}^\infty | h_{kl} |
      \sum_{t=1}^l Z_{i-k, t-l}^2 > a_n^2 \epsilon \right] \\
    &\leq& \sum_{k=0}^m \pr\left[c \sum_{l=0}^\infty | h_{kl} |
      \sum_{t=1}^l Z_{i-k, t-l}^2 > a_n^2 \epsilon \right] \\
    &\leq& \sum_{k=0}^m \pr\left[c \sum_{l=0}^\infty | h_{kl} |
      \sum_{q=0}^{l-1} Z_{i-k, -q}^2 > a_n^2 \epsilon \right] \\
  \end{eqnarray*}
  Using the fact that the sequence of $Z$ is iid and re-arranging the
  indices, we get
  \begin{eqnarray*}
    && \sum_{k=0}^m \pr\left[c \sum_{l=0}^\infty | h_{kl} |
      \sum_{q=0}^{l-1} Z_{i-k, -q}^2 > a_n^2 \epsilon \right] \\
    &=& \sum_{k=0}^m \pr\left[c \sum_{l=0}^\infty | h_{kl} |
      \sum_{q=0}^{l-1} Z_{i-k, q}^2 > a_n^2 \epsilon \right] \\
    &=& \sum_{k=0}^m \pr\left[c \sum_{q=0}^{\infty} Z_{i-k, q}^2
      \sum_{l=q+1}^\infty |h_{kl}| > a_n^2 \epsilon \right] \\
  \end{eqnarray*}
  Then by applying Jessen and Mikosch \cite{JessenMikosch2006} to the
  iid sequence of $(Z_{i-k, q}^2)_{q=0}^{\infty}$ we get
  \begin{eqnarray*}
    && \sum_{k=0}^m \pr\left[c \sum_{q=0}^{\infty} Z_{i-k, q}^2
      \sum_{l=q+1}^\infty |h_{kl}| > a_n^2 \epsilon \right] \\
    &\sim& \sum_{k=0}^m \pr(Z^2 > a_n^2 \epsilon/c) c_1
    \sum_{q=0}^{\infty} \left( \sum_{l=q+1}^\infty |h_{kl}|
    \right)^{\alpha/2} \\
    &\sim& c {L(n) \over n} \sum_{k=0}^m \sum_{q=0}^{\infty} \left(
      \sum_{l=q+1}^\infty |h_{kl}| \right)^{\alpha/2} \to 0
  \end{eqnarray*}
  where in the last step the assumption $\sum_{k=0}^{\infty}
  \left(\sum_{l=k}^{\infty} |h_{kl}|\right)^{\alpha/2-\epsilon} <
  \infty$, $\forall \epsilon > 0$ has been used.

  Because $p$ is assumed constant, the same arguments employed in
  \cite{Mikosch2014} can be applied here with $a_{np}$ replaced by
  $a_n$ to show
  \begin{eqnarray*}
    & \pr\left(
      a_n^{-2} \|\mtx I^{(2)}\|_2 > \epsilon
    \right) \to 0 \text{, } \forall \epsilon > 0 \text{ as } n \to
    \infty \\
    & \pr\left(
      a_n^{-2} \|\mtx I^{(3)}\|_2 > \epsilon
    \right) \to 0 \text{, } \forall \epsilon > 0 \text{ as } n \to \infty
  \end{eqnarray*}
\end{proof}
Next we show
\[
a_n^{-2}\sum_{q=-m}^p D_q M_q^{(m)}
\]
can be approximated by $a_n^{-2} D_{L_1} M_{L_1}^{(m)}$, where $L_1$ is the
index of $D_{(1)}$, i.e. $D_{L_1} = D_{(1)}$.
\begin{proof}
  \begin{eqnarray*}
    && a_n^{-2} \sum_{q=-m}^p D_q M_q^{(m)} \\
    &=& D_{L_1} a_n^{-2} \sum_{q=1}^{p-m+1} {D_{L_q} \over D_{L_1}}
    M_{L_q}^{(m)}
  \end{eqnarray*}
  By lemma \ref{lem:A}, ${D_{L_q} \over D_{L_1}} \xrightarrow{P} 0$,
  for $q = 2, \dots, p-m+1$ as $n \to \infty$.
\end{proof}
\begin{lemma}\label{lem:A}
  \begin{eqnarray*}
    \lim_{n \to \infty} \pr(a_n^{-2} {D_{(2)} \over D_{(1)}} >
    \epsilon) &=& 0
  \end{eqnarray*}
\end{lemma}
\begin{proof}
  Because $\pr(Z^2 > a_n^2) \sim {1 \over n}$, by CLT (see Mikosch et
  al \cite{Embrechts1997}, theorem 2.2.15), $a_n^{-2} \sum_{t=1}^n
  Z_t^2 \xrightarrow{d} \xi_{\alpha/2}$, where $\xi_{\alpha/2}$ is a
  $alpha/2$-stable r.v. Write $F$ for the df of
  $\xi_{\alpha/2}$ and $f$ for its density. Therefore
  \begin{eqnarray*}
    && \pr(a_n^{-2} {D_{(2)} \over D_{(1)}} > \epsilon) \\
    &=& \pr(a_n^{-2} {a_n^{-2} D_{(2)} \over a_n^{-2} D_{(1)}} >
    \epsilon) \\
    &=& \int_{\epsilon a_n^2} (p-m+1)p \bar{F}(x_2)^{n-2} f(x_1)
    f(x_2) 
  \end{eqnarray*}
\end{proof}


\subsection[alpha in (2,4)]{The case $\alpha \in (2,4)$}
In this case we have
\[
a_n^{-2} \|\mtx{X^{(m)} (X^{(m)})'} - \E(\mtx{X^{(m)} (X^{(m)})'}) -
\sum_{q=-m}^p (D_q - \E D) \mtx M_q^{(m)}\|_2
\xrightarrow{P} 0
\]
The proof is the same as its counterpart in \cite{Mikosch2014} except
that the approximating sequence in this case is $\sum_{q=-m}^p (D_q -
\E D) \mtx M_q^{(m)}$ and, because $p$ is fixed, this sequence doesn't
need further approximation.

\section{Lognormal Volatility Model}
We consider the model
\[
X_{it} = \sigma_{it} Z_{it}
\]
where $\pr(Z_{it} > x) = p_+ L(x) x^{-\alpha}$, $\pr(Z_{it} < -x) =
p_- L(x) x^{-\alpha}$ for a slowly varying function $L(x)$. $p_+ +
p_- = 1$ and $0 < \alpha < 4$.
\begin{eqnarray*}
  \ln \sigma_{it} = \sum_{k=0}^\infty \sum_{l=0}^\infty h_{k,l}
  \eta_{i-k,t-l}
\end{eqnarray*}
where $\eta_{i,t} \sim N(0, 1)$.

\bibliographystyle{unsrt}
\bibliography{../thesis/econophysics}
\end{document}
