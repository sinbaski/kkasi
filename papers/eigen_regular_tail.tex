\documentclass{article}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage[bookmarks=true]{hyperref}
\usepackage{bookmark}

\input{../physics_common}
\begin{document}
\section{iid sequences}\label{sec:iid}
Consider iid sequences $\{X_{it}\}$, $1 \leq i \leq p$, $1 \leq t \leq
n$. $p$ is fixed while $n \to \infty$. $\pr(X_{it} > x) = p_+ L(x)
x^{-\alpha}$, $\pr(X_{it} < -x) = p_- L(x) x^{-\alpha}$ for a slowly
varying function $L(x)$, and $p_+ + p_- = 1$. The normalizing sequence
$a_n$ is such that $\pr(|x_{it}| > a_n) \sim {1 \over n}$, implying
$a_n \sim n^{1/\alpha} l(n)$, where $l(n)$ is a slowing varying
function. Moreover, we assume $\E X_{11} = 0$ if $\E |X_{11}| <
\infty$. The sample covariance matrix is $\mtx {XX'}$.

For convenience, we let $c$ stand for any constant whose value is not
of importance in the rest of this report. We shall prove
\[
a_n^{-2}\|\mtx {XX'} - \diag(\mtx {XX'})\|_2 \xrightarrow{P} 0
\]

\begin{proof}
  Using the inequality
  \[
  \|\mtx A\|_2 \leq \|\mtx A\|_\infty
  \]
  for an arbitrary matrix $\mtx A$, we have
  \begin{align*}
    \pr(\|\mtx {XX'} - \diag(\mtx {XX'})\|_2 \geq a_n^2 \epsilon) & \leq
    \pr\left(\max_{1\leq i \leq p} \sum_{j=1, j\neq i}^p |\sum_{t=1}^n
    X_{it} X_{jt}| > a_n^2 \epsilon\right) \\
    &\leq \sum_{i=1}^p \sum_{j=1, j\neq i}^p \pr\left(|\sum_{t=1}^n
    X_{1t} X_{2t}| > {a_n^2 \epsilon \over p-1}\right) \\
  \end{align*}
  When $\E|X_1 X_2| < \infty$, $\E|X_1| =\sqrt{\E|X_1 X_2|} < \infty$.
  By assumption $\E X_1 = 0$ and hence $\E X_1 X_2 = (\E X_1)^2 = 0$.
  Thus the large deviation result found in Cline and Hsing
  \cite{ClingHsing1998} and Nagaev \cite{nagaev1979} is
  applicable. With it we obtain
  \begin{align*}
    \pr\left(|\sum_{t=1}^n X_{1t} X_{2t}| > {a_n^2 \epsilon \over p-1}\right)
    &\sim
    c n \pr\left(|X_{11} X_{21}| > {a_n^2 \epsilon \over p-1 }\right)
  \end{align*}
  Now that $|X_{11}|$ and $|X_{21}|$ are iid and regularly varying
  with index $\alpha$, so is $|X_{11} X_{21}|$, according to Jessen
  and Mikosch \cite{JessenMikosch2006}. Thus we have
  \begin{eqnarray*}
    c n \pr\left(|X_{11} X_{21}| > {a_n^2 \epsilon \over p-1 }\right)
    &\sim& c n L_{12}(n) (n^{2/\alpha})^{-\alpha} \to 0\text{,  }n\to\infty
  \end{eqnarray*}
  where $L_{12}$ is a slowly varying function.
\end{proof}
Now, using the result just proved and applying Weyl's perturbation
theorem we obtain
\[
a_n^{-2} \max_{i=1,\dots,p} |\lambda^C_{(i)} -
\lambda^{\text{diag}}_{(i)}| \leq  a_n^{-2}\|C - \diag{C}\| \to 0
\]
Therefore the eigenvalues of $C$ can be approximated by those of
$\diag(C)$:
\begin{eqnarray*}
a_n^{-2}\lambda^{\text{diag}}_{i}  &=& a_n^{-2} \sum_{t=1}^n X_{it}^2
\end{eqnarray*}

\subsection{Upper Order Statistics of the eigenvalues}
When $\alpha \in (0,2)$, $\E X^2 = \infty$. Now that
$\pr(X_{11}^2 > a_n^2) \sim 1/n$, the central limit theorem 
gives, according to Mikosch et al\cite{Embrechts1997} 
\[
a_n^{-2} \sum_{t=1}^n X_{it}^2 \xrightarrow{d} \xi_i \sim S_{\alpha/2}
\]
where $S_{\alpha/2}$ denotes an $\alpha/2$-stable distribution.
Since $(\xi_i)_{i=1}^p$ are iid, the joint density function of the $k$
upper order statistics of $\lambda_i$, the eigenvalues of $a_n^{-2} X X'$
follows as
\begin{eqnarray*}
  f_{\lambda_{(1)}, \dots, \lambda_{(k)}}(x_1, \dots, x_k) &=&
  p(p-1)\cdots(p-k+1) S_{\alpha/2}^{p-k}(x_k) \prod_{i=1}^k
  f_{\alpha/2}(x_i)
\end{eqnarray*}
where $f_{\alpha/2}(x) = {d S_{\alpha/2}(x) \over dx}$.

When $\alpha \in (2,4)$ the central limit theorem gives
\[
a_n^{-2} (\sum_{t=1}^n X_{it}^2 - n \E X^2)\xrightarrow{d}
\xi_i \sim S_{\alpha/2}
\]
Since $a_n \sim n^{1/\alpha} l(n)$, it is clear
\[
a_n^{-2} \sum_{t=1}^n X_{it}^2 \xrightarrow{a.s}\infty
\]

\section{Correlated Sequences}
\subsection{MA(1) process}
First consider the model
\[
X_{it} = Z_{it} + \theta Z_{i,t-1}
\]
We have
\begin{eqnarray*}
  a_n^{-2}(XX')_{ij} &=& a_n^{-2} \sum_{t=1}^n (Z_{it} + \theta
  Z_{i,t-1}) (Z_{jt} + \theta Z_{j,t-1}) \\
  &=& a_n^{-2} \sum_{t=1}^n Z_{it} Z_{jt} + a_n^{-2} \theta \sum_{t=1}^n
  Z_{it} Z_{j,t-1} \\
  && +\theta a_n^{-2} \sum_{t=1}^n Z_{i, t-1}
  Z_{j,t} + \theta^2 a_n^{-2} \sum_{t=1}^n Z_{i,t-1} Z_{j,t-1}
\end{eqnarray*}
Consider $\pr(a_n^{-2} \sum_{t=1}^n Z_{1t} Z_{2t} > \epsilon)$,
$\forall \epsilon>0$. Since $Z_1 Z_2 \in \mathcal R_{-\alpha}$ (See
Mikosch and Jessen \cite{JessenMikosch2006}) and $\E Z_1 Z_2 = 0$ if
$\E|Z_1Z_2| < \infty$. By the large deviation result of Cline and
Hsing \cite{ClingHsing1998} and Nagaev \cite{nagaev1979}
\begin{eqnarray*}
  && \pr(a_n^{-2} \sum_{t=1}^n Z_{1t} Z_{2t} > \epsilon)  \\
  &\sim& c n \pr(|Z_1 Z_2| > a_n^{2} \epsilon)  \\
\end{eqnarray*}
Because $a_n \sim n^{1/\alpha} l(n)$, we have
\begin{eqnarray*}
  \pr(|Z_1 Z_2| > a_n^{2} \epsilon) &\sim& n^{-2} L_{12}(n)
\end{eqnarray*}
where $L_{12}(n)$ is a slowly varying function. Thus
\[
\pr(a_n^{-2} \sum_{t=1}^n Z_{1t} Z_{2t} > \epsilon) \to 0
\]

On the other hand $Z^2 \in \mathcal R_{-\alpha/2}$, hence
\begin{eqnarray*}
  \pr(a_n^{-2} \sum_{t=1}^n Z_{1t}^2 > \epsilon) &\sim& c n
  \pr(Z_{1t}^2 > a_n^2 \epsilon) \\
  &\sim& c n \pr(|Z_{1t}| > a_n) \\
  &\sim& c L(n)
\end{eqnarray*}
Therefore
\begin{eqnarray*}
  \pr(a_n^{-2} \sum_{t=1}^n Z_{it} Z_{jt}\I{i \neq j} > \epsilon) \to
  0 \\
  \pr(a_n^{-2} \sum_{t=1}^n Z_{i,t-1} Z_{j,t-1} \I{i \neq j} >
  \epsilon) \to 0 \\
  \pr(a_n^{-2} \sum_{t=1}^n Z_{it} Z_{j,t-1} > \epsilon) \to 0
  \\
  \pr(a_n^{-2} \sum_{t=1}^n Z_{i, t-1} Z_{j,t} > \epsilon) \to 0
\end{eqnarray*}
Then it follows, for $i \neq j$, i.e. non-diagonal entries,
$\pr(a_n^{-2} (XX')_{ij} > \epsilon) \to 0$; and for diagonal entries
\begin{eqnarray*}
  && \pr\left[(XX')_{ii} - (1 + \theta^2)\sum_{t=1}^n
      Z_{it}^2 > a_n^{2} \epsilon \right] \\
  &=& \pr\left[\theta^2 ( Z_{0}^2-Z_{n}^2) > a_n^{2} \epsilon
  \right] \to 0\\
\end{eqnarray*}
So for the eigenvalues of $a_n^{-2}XX'$, $\lambda_{(1)} > \lambda_{(2)} >
\dots > \lambda_{(p)}$, we have
\[
(\lambda_{(1)}, \lambda_{(2)}, \dots, \lambda_{(p)}) \xrightarrow{P}
(1+\theta^2)(\sum_{t=1}^n Z_{1t}^2, \sum_{t=1}^n Z_{2t}^2, \dots,
\sum_{t=1}^n Z_{pt}^2)
\]
As argued in the iid case in \S\ref{sec:iid}, if $\alpha \in (0,2)$,
$\sum_{t=1}^n Z_{it}^2 \xrightarrow{d} \xi_{i}$, where $\xi_{i}$ is an
$\alpha/2$-stable rv; if $\alpha \in (2,4)$, $\sum_{t=1}^n Z_{it}^2
\xrightarrow{a.s.} \infty$.

\subsection{Cross-correlation limited to order 1}\label{sec:B1}
Now we consider the model
\[
X_{it} = Z_{it} + \varphi Z_{i-1,t}
\]
\begin{eqnarray*}
  (XX')_{ij} &=& \sum_{t=1}^n (Z_{it} + \varphi Z_{i-1,t})(Z_{jt} +
  \varphi Z_{j-1,t}) \\
  &=& \sum_{t=1}^n (Z_{it}^2 + \varphi^2 Z_{i-1,t}^2)\I{i=j}
  + \sum_{t=1}^n (Z_{it}Z_{jt}+\varphi^2 Z_{i-1,t}Z_{j-1,t})\I{i\neq j}
  \\
  && + \varphi \sum_{t=1}^n Z_{it}^2 \I{i=j-1} 
  +\varphi\sum_{t=1}^n Z_{it} Z_{j-1,t}\I{i\neq j-1} \\
  && + \varphi \sum_{t=1}^n Z_{i-1,t}^2 \I{i=j+1} 
  +\varphi\sum_{t=1}^n Z_{jt} Z_{i-1,t}\I{i\neq j+1} \\
\end{eqnarray*}
As shown in previous sections, $\pr(a_n^{-2} \sum_{t=1}^n Z_{1t}Z_{2t} >
\epsilon) \to 0$, as $n \to \infty$. Therefore
\[
\pr\left(
  (XX')_{ij} - A_{ij}> a_n^2 \epsilon \right) \to 0\text{,  }n \to 0
\]
where
\[
A_{ij} = \sum_{t=1}^n (Z_{it}^2 + \varphi^2 Z_{i-1,t}^2)\I{i=j}
      + \varphi \sum_{t=1}^n Z_{it}^2 \I{i=j-1} 
      + \varphi \sum_{t=1}^n Z_{i-1,t}^2 \I{i=j+1}
\]
If $\alpha \in (0,2)$, $a_n^{-2}\sum_{t=1}^n Z_{it}^2 \xrightarrow{d}
\xi_i \sim S_{\alpha/2}$. So we have in this case
\[
A =
\begin{pmatrix}
  \xi_1 + \varphi^2 \xi_0 & \varphi \xi_1 & 0 & \cdots & 0 \\
  \varphi \xi_1 & \xi_2 + \varphi^2 \xi_1 & \varphi \xi_2 & \cdots & 0 \\
  0 & \varphi \xi_2 & \xi_3 + \varphi^2 \xi_2 & \cdots & 0 \\
  \vdots & \vdots & \vdots & \ddots & \vdots \\
  0 & 0 & 0 & \cdots & \xi_p + \varphi^2 \xi_{p-1}
\end{pmatrix}
\]

\subsection{cross- \& auto-correlation limited to order 1}
Here we consider the mode
\[
X_{it} = Z_{it} + \theta Z_{i, t-1} + \varphi Z_{i-1, t}
\]
The calculations are similar to those in \S\ref{sec:B1}. For clearity
we write $A_{ij} \sim B_{ij}$ if $\pr(|A_{ij} - B_{ij}| > a_n^2 \epsilon)
\to 0$, $\forall \epsilon > 0$ and $n \to \infty$. Then we have
\begin{eqnarray*}
  (XX')_{ij} &\sim& \left[
    \sum_{t=1}^n Z_{it}^2 + \theta^2 \sum_{t=1}^n Z_{i,t-1}^2 +
    \varphi^2 \sum_{t=1}^n Z_{i-1,t}^2 
  \right]\I{i=j} \\
  && + \varphi \left[
    \sum_{t=1}^n Z_{it}^2 \I{i=j-1} + \sum_{t=1}^n Z_{i-1, t}^2 \I{i=j+1}
  \right]
\end{eqnarray*}
When $\alpha \in (0,2)$, the matrix $A$ comprising the entries on the
right-hand-side of the above expression is
\[
A =
\begin{pmatrix}
  (1 + \theta^2)\xi_1 + \varphi^2 \xi_0 & \varphi \xi_1 & 0 & \cdots & 0 \\
  \varphi \xi_1 & (1 + \theta^2)\xi_2 + \varphi^2 \xi_1 & \varphi \xi_2 & \cdots & 0 \\
  0 & \varphi \xi_2 & (1 + \theta^2)\xi_3 + \varphi^2 \xi_2 & \cdots & 0 \\
  \vdots & \vdots & \vdots & \ddots & \vdots \\
  0 & 0 & 0 & \cdots & (1 + \theta^2)\xi_p + \varphi^2 \xi_{p-1}
\end{pmatrix}
\]
where each $\xi_i \sim S_{\alpha/2}$.

\subsection{A more general model}
Now we consider the case
\begin{eqnarray*}
  X_{it} &=& \sum_{l=0}^\infty \theta_l Z_{i,t-l} + \sum_{k=0}^\infty
  \varphi_k Z_{i-k,t}
\end{eqnarray*}
\subsubsection[alpha in (0,2)]{In case $\alpha \in (0,2)$}
In this case we have
\begin{eqnarray*}
  (XX')_{ij} &=& \sum_{t=1}^n \sum_{l=0}^\infty \sum_{l'=0}^\infty
  \theta_l\theta_{l'} Z_{i,t-l} Z_{j,t-l'} + \\
  && \sum_{t=1}^n \sum_{k=0}^\infty \sum_{k'=0}^\infty \varphi_{k'}
  Z_{i-k,t} \varphi_k Z_{j-k,t} \\
  && \sum_{t=1}^n \sum_{k=0}^\infty \sum_{l=0}^\infty \varphi_k
  Z_{i-k,t} \theta_l Z_{j,t-l} \\
  && \sum_{t=1}^n \sum_{k=0}^\infty \sum_{l=0}^\infty \varphi_k
  Z_{j-k,t} \theta_l Z_{i,t-l} \\
  &=& I^{(1)}_{ij} + I^{(2)}_{ij} + I^{(3)}_{ij} + I^{(4)}_{ij}
\end{eqnarray*}
\begin{eqnarray*}
  I^{(1)}_{ij} &=& \sum_{t=1}^n \sum_{l=0}^\infty \theta_{l}^2
  Z_{i,t-l}^2 \I{i=j}\\
  && + \sum_{t=1}^n \sum_{l=0}^\infty \sum_{\substack{l'=0 \\l'\neq
      l}}^\infty \theta_l\theta_{l'} Z_{i,t-l} Z_{i,t-l'} \I{i=j} \\
  && + \sum_{t=1}^n \sum_{l=0}^\infty \sum_{l'=0}^\infty
  \theta_l\theta_{l'} Z_{i,t-l} Z_{j,t-l'} \I{i\neq j} \\
  &=& I^{(11)}_{i,j} + I^{(12)}_{i,j} + I^{(13)}_{i,j} \\
\end{eqnarray*}
First we look into $I^{(12)}_{i,j}$. Notice that $Z_{i,t-l}
Z_{i,t-l'} \in \mathcal R_{-\alpha}$ when $l \neq l'$. In addition $\E
Z_{i,t-l} Z_{i,t-l'} = 0$ if $\E|Z_{i,t-l} Z_{i,t-l'}| < \infty$, by
assumption. Thus the large deviation results by Cline and Hsing
\cite{ClingHsing1998} and Nagaev \cite{nagaev1979} give
\begin{eqnarray*}
  && \pr(|I^{(12)}_{i,j}| > a_n^2 \epsilon) \\
  &\sim& \pr\left[\left|
    \sum_{t=1}^n \sum_{l=0}^\infty \sum_{\substack{l'=0 \\l'\neq
        l}}^\infty \theta_l\theta_{l'} Z_{t-l} Z_{t-l'} \right|
    > a_n^2 \epsilon\right] \\
  &\leq& \pr\left[
    \sum_{t=1}^n \sum_{l=0}^\infty \sum_{\substack{l'=0 \\l'\neq
        l}}^\infty \left|\theta_l\theta_{l'} Z_{t-l} Z_{t-l'} \right|
    > a_n^2 \epsilon\right]
\end{eqnarray*}
Write $s_{t,l,l'}$ for $\left|Z_{t-l} Z_{t-l'}\right|\I{l\neq
  l'}$. Then we have
\begin{eqnarray*}
  && \pr(|I^{(12)}_{i,j}| > a_n^2 \epsilon) \\
  &=& \pr\left[
    \sum_{t=1}^n \sum_{l=0}^\infty \sum_{\substack{l'=0 \\l'\neq
        l}}^\infty |\theta_l \theta_{l'}| \left(s_{tll'} \I{|\theta_l \theta_{l'}|s_{tll'} \leq a_n^2
        \epsilon/2} + s_{tll'} \I{|\theta_l \theta_{l'}|s_{tll'} > a_n^2
        \epsilon/2}\right) > a_n^2 \epsilon\right] \\
  &\leq& \pr\left[
    \sum_{t=1}^n \sum_{l=0}^\infty \sum_{\substack{l'=0 \\l'\neq
        l}}^\infty |\theta_l \theta_{l'}|s_{tll'} \I{|\theta_l \theta_{l'}|s_{tll'} \leq a_n^2 \epsilon/2} >
    a_n^2 \epsilon/2\right] \\
  && + \pr\left[
    \sum_{t=1}^n \sum_{l=0}^\infty \sum_{\substack{l'=0 \\l'\neq
        l}}^\infty |\theta_l \theta_{l'}|s_{tll'} \I{|\theta_l \theta_{l'}|s_{tll'} > a_n^2 \epsilon/2} >
    a_n^2 \epsilon/2\right] \\
  &=& P_1 + P_2
\end{eqnarray*}
Applying Markov's inequality we obtain
\begin{eqnarray*}
  P_1 &\leq& 2 a_n^{-2} \epsilon^{-1}
    \sum_{t=1}^n \sum_{l=0}^\infty \sum_{\substack{l'=0 \\l'\neq
        l}}^\infty |\theta_l \theta_{l'}| \E s_{tll'} \I{|\theta_l
      \theta_{l'}|s_{tll'} \leq a_n^2 \epsilon/2}
\end{eqnarray*}
For a $\beta > \max(\alpha, 1)$ we have by Jensen's inequality
\begin{eqnarray*}
  \E s_{tll'} \I{|\theta_l \theta_{l'}|s_{tll'} \leq a_n^2 \epsilon/2} &\leq&
  \left[
    \E s_{tll'}^{\beta} \I{|\theta_l \theta_{l'}|s_{tll'} \leq a_n^2 \epsilon/2}
  \right]^{1/\beta}
\end{eqnarray*}
Since $s_{tll'} \in \mathcal R_{-\alpha}$, Karamata's theorem leads
to
\begin{eqnarray*}
  \E s_{tll'}^{\beta} \I{|\theta_l \theta_{l'}|s_{tll'} \leq a_n^2 \epsilon/2} &\sim&
  c \pr(s_{tll'} > a_n^2) a_n^{2\beta} \\
  &\sim& L_{12}(a_n) a_n^{2(\beta - \alpha)}
\end{eqnarray*}
Thus we have
\begin{eqnarray*}
  P_1 &\leq& n L'_{12}(a_n) a_n^{2(1 - \alpha/\beta)-2}
  \sum_{l=0}^\infty \sum_{\substack{l'=0 \\l'\neq l}}^\infty |\theta_l
  \theta_{l'}| \\
  &\leq& l_{12}(n) n^{-2/\beta + 1} \to 0
\end{eqnarray*}
For $P_2$ we have
\begin{eqnarray*}
  P_2 &=& \pr\left[
    \sum_{t=1}^n \sum_{l=0}^\infty \sum_{\substack{l'=0 \\l'\neq
        l}}^\infty |\theta_l \theta_{l'}|s_{tll'} \I{|\theta_l
      \theta_{l'}|s_{tll'} > a_n^2 \epsilon/2} > a_n^2
    \epsilon/2\right] \\
  &\leq& \pr\left[
    \sum_{t=1}^n \sum_{l=0}^\infty \sum_{\substack{l'=0 \\l'\neq
        l}}^\infty |\theta_l \theta_{l'}|s_{tll'} \mathbf{1}_{A_{ll'}}
    > a_n^2 \epsilon/2\right]
\end{eqnarray*}
where the sets $A_{ll'}$ are
\begin{eqnarray*}
  A_{ll'} &=& \left\{
    \exists t:\sum_{l,l' \geq 0, l\neq l'}|\theta_l
    \theta_{l'}|s_{tll'} > a_n^2 \epsilon/2\right\}
\end{eqnarray*}
Then it follows
\begin{eqnarray*}
  P_2 &\leq& \pr\left(
    \bigcup_{t=1}^{n} A_{ll'}
  \right) \\
  &\leq& n\pr\left(\sum_{l,l' \geq 0, l\neq l'}|\theta_l
    \theta_{l'}|Z_1Z_{2} > a_n^2 \epsilon/2\right) \\
  &\sim& c n a_n^{-2\alpha} \\
  &\sim& c n^{-1} l_1(n)\to 0
\end{eqnarray*}
where $l_1(\cdot)$ is a slowly varying function.
\bibliographystyle{unsrt}
\bibliography{../thesis/econophysics}
\end{document}
