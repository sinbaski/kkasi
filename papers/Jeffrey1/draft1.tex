\documentclass{article}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage[bookmarks=true]{hyperref}
\usepackage{bookmark}
\usepackage{graphicx}

\input{../../physics_common}
\title{Importance Sampling}
\author{Xie Xiaolei}
\date{\today}

\begin{document}
\maketitle
\section{Introduction}
We consider the model
\begin{eqnarray*}
V_n &=& A_n V_{n-1} \\
V_0 &=& x_0 \in \mathbb S^{d-1}\\
\end{eqnarray*}
Use the following notations
\begin{eqnarray*}
X_n &=& \frac{V_n}{\|V_n\|} \\
S_n &=& \log \|A_n \cdots A_1 x_0\| \\
\xi_n &=& S_n - S_{n-1} = \log\frac{\|A_n \cdots A_1 x_0\|}{\|A_{n-1}
  \cdots A_1 x_0\|} \\
&=& \log\left\| A_n \frac{A_{n-1} \cdots A_1 x_0}{\|A_{n-1} \cdots A_1
    x_0\|} \right\|\\
&=& \log \|A_n X_{n-1}\|
\end{eqnarray*}
The pair $(X_n, S_n)$ is a Markov additive process with transition
kernel $P$. Assume conditions (M) and (A) of Kesten \cite{Kesten1973}:
\begin{enumerate}
\item The top Lyapunov exponent is negative, i.e.
  \begin{equation}
    \label{eq:neg_top_Lyapunov}
    \inf_{n \geq 1} \E \log \|A_n \cdots A_1\| < 0    
  \end{equation}
\item $\exists \xi > 0$ such that $\lambda(\xi) = 1$, where
  $$
  \lambda(\xi) := \inf_{n \geq 1} (\E \|A_n \cdots A_1\|^\xi)^{1/n}
  $$
\item $\E[\|A\|^\xi \log^+\|A\|] < \infty$
\end{enumerate}

\section{Consistency}\label{sec:consistency}
By the law of large numbers
\begin{eqnarray*}
  && \P(|V| > u) \\
  &=& \lim_{n \to \infty} {1 \over n} \sum_{i=0}^n \1{|V_i| > u}
\end{eqnarray*}
Define
\[
R_n := \inf\{0 \leq i \leq n: V_i \in \mathcal C\}
\]
and
\[
K_i := \inf\{k \geq 1: k > K_{i-1}, V_k \in \mathcal C, K_0 = 0\}
\]
Then one can write
\begin{eqnarray*}
  && \lim_{n \to \infty} {1 \over n} \sum_{i=1}^n \1{|V_i| > u} \\
  &=& \lim_{n \to \infty} {1 \over n} \left[
    \sum_{i=0}^{K_{R_n}-1} \1{|V_i| > u} + \sum_{i=K_{R_n}}^n \1{|V_i| > u}
\right]
\end{eqnarray*}
For the 2nd term, by a Borel-Cantelli argument, it maybe shown
\[
\lim_{n \to \infty} {1 \over n}\sum_{i=K_{R_n}}^n \1{|V_i| > u} = 0
\]
For the 1st term,
\begin{eqnarray*}
&& \lim_{n \to \infty} {1 \over n} \sum_{i=0}^{K_{R_n}-1} \1{|V_i| >
  u}  \\
&=& \lim_{n \to \infty} {R_n \over n} {1 \over R_n} \sum_{i=1}^{R_n}
\sum_{j=K_{i-1}}^{K_i-1}\1{|V_i| > u} \\
&=& \pi(\mathcal C) \E_\gamma N_u
\end{eqnarray*}
where the law of large numbers of Markov chains has been used to reach
the last line. In addition, it is assumed
\begin{eqnarray*}
  V_{K_i} &\sim& \gamma \; \forall i \geq 0 \\
  \gamma(E) &=& \pi(E)/\pi(\mathcal C)\; \forall E \in \mathcal
  B(\mathcal C)
\end{eqnarray*}
Define
\begin{eqnarray*}
  T_u &=& \inf\{n \geq 1: |V_n| > u\} \\
  \tau &\overset{d}{=}& K_i - K_{i-1} \\
  N_u &:=& \sum_{i=0}^{\tau-1} \1{|V_i| > u}  \\
\end{eqnarray*}
Then $\E_\gamma N_u$ may be evaluated as
\begin{eqnarray*}
  && \E_\gamma N_u \\
  &=& \E_\gamma N_u \1{T_u < \tau} \\
  &=& \int_{\mathds S^{d-1}} \int_{\mathds R} \cdots \int_{\mathds
    S^{d-1}} \int_{\mathds R} N_u \1{T_u < \tau} \times \\
  && \prod_{i=1}^{T_u} e^{-\xi(s_i - s_{i-1}) + \Lambda(\xi)}
  {r(x_{i-1}; \xi) \over r(x_{i}; \xi)}P_\xi(x_{i-1}, dx_i \times ds_i) \times \\
  && \prod_{i=T_u+1}^{\tau-1} P(x_{i-1}, dx_i \times d s_i) \\
  &=& \E_{\mathcal D} \left[
    N_u \1{T_u < \tau} e^{-\xi S_{T_u}} {r(x_0; \xi)
      \over r(x_{T_u}; \xi)}
  \right]
\end{eqnarray*}
where
\[
P_\xi(x_{i-1}, dx_i \times ds_i) = e^{\xi(s_i - s_{i-1}) -
  \Lambda(\xi)} {r(x_i; \xi) \over r(x_{i-1}; \xi)} P(x_{i-1}, dx_i
\times ds_i)
\]
is the $\xi$-shifted transition kernel of the {\it Markov Additive
  process} $(X_n, S_n)$. $\xi$ is chosen such that 
\[
\Lambda(\xi) = \lim_{n \to \infty} \log \left(
\E \|A_n \cdots A_1\|^\xi
\right)^{1/n} = 0
\]
$\E_{\mathcal D}$ denotes expectation taken with respect to the dual
measure defined as
\[
P_{\mathcal D} (x_i, dx_{i+1} \times ds) = \left\{
  \begin{array}{ll}
    P_\xi (x_i, dx_{i+1} \times ds) & \text{ if } i < T_u \\
    P(x_i, dx_{i+1} \times ds) & \text{ if } i \geq T_u \\
  \end{array}
\right.
\]
Because the top Lyapunov exponent is negative, it follows from a lemma
in Kesten \cite{Kesten1973} that there is a $s > 0$ such that
$\Lambda(s) < 0$.

Thus we have obtained a consistent estimator
$\mathcal E_u$ for $\P(|V| > u)$:
\begin{eqnarray*}
\P(|V| > u) &=& \pi(\mathcal C) \E_{\mathcal D} \mathcal E_u \\
&=& \pi(\mathcal C) \E_{\mathcal D} \left[
  N_u \1{T_u < \tau} e^{-\xi S_{T_u}} {r(x_0; \xi)
    \over r(x_{T_u}; \xi)}
\right]
\end{eqnarray*}

\section{Efficiency}\label{sec:efficiency}
\begin{theorem}
  The estimator $\mathcal E_u$ has bounded relative error, i.e.
  \begin{equation*}
    {\var(\mathcal E_u) \over [\E_D \mathcal E_u]^2} < \infty
  \end{equation*}
\end{theorem}
\begin{proof}
  The claim is equivalent to
  \[
  {\E_D \mathcal E_u^2 \over (\E_D \mathcal E_u)^2} < \infty
  \]
  By Kesten's theorem \cite{Kesten1973}, $\P(|V| > u) \sim C
  u^{-\xi}$. Hence, to prove the claim, one needs to check
  $u^{2\xi}\E_D \mathcal E_u^2 < \infty$, i.e.
  \[
  u^{2\xi} \E_D  \left[ 
    N_u^2 \1{T_u < \tau} e^{-2\xi S_{T_u}} {r^2(x_0; \xi)
      \over r^2(x_{T_u}; \xi)}\right]
  < \infty
  \]
\end{proof}

\subsection{The Drift Condition}
%%% What follows is the proof in the 1D case.
% Consider
% \begin{eqnarray*}
%   && \int_E |y|^\alpha P_\beta(v, dy)  \\
%   &=& \int_E |A_n v + B_n|^\alpha \P_\beta\left(V_n \in [y, y +dy) |
%   V_{n-1} = v\right) \\
% &=& \int_{R^3} |A_n v + B_n|^\alpha d\mu_\beta(\log A_n, B_n, D_n) \\
% &=& \E_\beta |A_n v + B_n|^\alpha
% \end{eqnarray*}
% \begin{enumerate}[(i)]
% \item if $\alpha < 1$, $|\cdot|^\alpha$ is a concave and hence
%   subadditive function. We have
%   \begin{eqnarray*}
%     && \E_\beta |A_n v + B_n|^\alpha    \\
%     &\leq& |v|^{\alpha}\E_\beta|A_n|^\alpha + \E_\beta|B_n|^\alpha \\
%     &\leq& |v|^{\alpha}\left(
%       \E_\beta|A_n|^\alpha + |v|^{-\alpha}\E_\beta|B_n|^\alpha
%     \right)\\
%   \end{eqnarray*}
%   Clearly
%   \begin{eqnarray*}
%     \inf_{v} \left(
%       \E_\beta|A_n|^\alpha + |v|^{-\alpha}\E_\beta|B_n|^\alpha
%     \right) = \E_\beta|A_n|^\alpha
%   \end{eqnarray*}
%   Therefore, if there exists an $\alpha > 0$ such that
%   $\E_\beta|A_n|^\alpha < 1$, $|v|$ can be chosen sufficiently large
%   so that $\E_\beta|A_n|^\alpha + |v|^{-\alpha}\E_\beta|B_n|^\alpha <
%   1$. By definition,
%   \begin{eqnarray*}
%     && \E_\beta |A_n|^\alpha \\
%     &=& \int_{R^3} |A_n|^{\alpha + \beta} d\mu(\log A_n, B_n, D_n)
%     \times \\
%     && \left[
%       \int_{R^3} |A_n|^{\beta} d\mu(\log A_n, B_n, D_n)
%     \right]^{-1} \\
%     &=& {\E |A_n|^{\alpha + \beta} \over \E |A_n|^{\beta}}
%   \end{eqnarray*}
%   Since $\E|A_n|^{\zeta}$ is convex and by
%   assumption, $\E|A_n|^{\xi} =\E|A_n|^0= 1$, it immediately follows
% \[
% \exists s \in (0, \xi), \E |A_n|^s = \inf_{\zeta \in (0, \xi)} \E
% |A_n|^\zeta < 1
% \]
% Thus, for any given $\alpha \in (0, \xi)$, one can always find
% $\beta\in [0, \xi-\alpha]$ such that $\E_\beta |A_n|^\alpha = {\E
%   |A_n|^{\alpha + \beta} \over \E |A_n|^{\beta}} < 1$. Once $\beta$
% has been chosen accordingly, one can choose $v \notin (-M_\beta,
% M_\beta)$ so that $\E_\beta|A_n|^\alpha +
% |v|^{-\alpha}\E_\beta|B_n|^\alpha < 1$. Here
% \[
% M_\beta = \left({\E_\beta |B_n|^\alpha \over 1 - \E_\beta
%     |A_n|^\alpha}\right)^{1/\alpha}
% \]

% \item if $\alpha \geq 1$, by Minkowskii inequality,
%   \begin{eqnarray*}
%     && \E_\beta |A_n v + B_n|^\alpha \\
%     &\leq& |v|^\alpha\left[
%       (\E_\beta|A_n|^\alpha)^{1/\alpha} + {(\E_\beta
%         |A_n|^\alpha)^{1/\alpha} \over |v|}
%     \right]^\alpha
%   \end{eqnarray*}
%   The same arguments as in the $\alpha < 1$ case apply. But in this
%   case we have
%   \[
%   M_\beta = \left[{
%     (\E_\beta |B_n|^\alpha)^{1/\alpha}
%     \over
%     1 - (\E_\beta|A_n|^\alpha)^{1/\alpha}
%   }\right]^{1/\alpha}
% \]
In this section we prove
\[
\E \left[ |V_n|^\alpha r_\alpha(\tilde V_n) | F_{n-1} \right] \leq
\rho |V_{n-1}|^\alpha r_\alpha(\tilde V_{n-1})
\]
for some $\rho < 1$.
\begin{proof}
  \begin{eqnarray*}
    && \E \left[ |V_n|^\alpha r_\alpha(\tilde V_n) | F_{n-1} \right]
    \\
    &=& \E\left[\int_{S^{d-1}} \inn{V_n, y}^\alpha dl^*_\alpha(y)|
      F_{n-1} \right]
    \\
    &\leq& \E\left[\int_{S^{d-1}} (\inn{A_n V_{n-1}, y} + \inn{B_n,
        y})^\alpha dl^*_\alpha(y) | F_{n-1} \right]
  \end{eqnarray*}
  \begin{enumerate}[(i)]
  \item if $\alpha < 1$, by subadditivity we have
    \begin{eqnarray*}
      &&\E\left[\int_{S^{d-1}} (\inn{A_n V_{n-1}, y} + \inn{B_n,
          y})^\alpha dl^*_\alpha(y) | F_{n-1} \right]\\
      &\leq& \E\left[\int_{S^{d-1}} \inn{A_n V_{n-1}, y}^\alpha
        dl^*_\alpha(y) | F_{n-1} \right]
      + \E\left[\int_{S^{d-1}} \inn{B_n, y}^\alpha dl^*_\alpha(y) |
        F_{n-1} \right] \\
      &=& \E\left[|V_{n-1}|^\alpha |A_n \tilde V_{n-1}|^\alpha\int_{S^{d-1}}
        \inn{{A_n V_{n-1} \over |A_n V_{n-1}|}, y}^\alpha
        dl^*_\alpha(y) | F_{n-1} \right] \\
      && + \E\left[\int_{S^{d-1}} \inn{B_n, y}^\alpha dl^*_\alpha(y) |
        F_{n-1} \right] \\
      &=& |V_{n-1}|^\alpha \left\{
        (P_\alpha r_\alpha)(\tilde V_{n-1}) +
        {1 \over |V_{n-1}|^\alpha} \E |B_n|^\alpha r_\alpha(\tilde
        B_n) \right\} \\
      &=& |V_{n-1}|^\alpha r_\alpha(\tilde V_{n-1})\left\{
        \lambda(\alpha) +
        {1 \over |V_{n-1}|^\alpha r_\alpha(\tilde V_{n-1})} \E
        |B_n|^\alpha r_\alpha(\tilde B_n) \right\} \\
    \end{eqnarray*}
    Clearly $\E\left[|B_n|^\alpha r_\alpha(\tilde B_n)\right] <
    \infty$. Hence the infimum of the expression in the curly bracket
    over all $n \geq 1$ is $\lambda(\alpha) < 1$. Therefore, when
    $|V_{n-1}|$ is sufficiently large, we have
    \[
    \E \left[ |V_n|^\alpha r_\alpha(\tilde V_n) | F_{n-1} \right] \leq
    \rho |V_{n-1}|^\alpha r_\alpha(\tilde V_{n-1})
    \]
    
  \end{enumerate}    
\end{proof}

\bibliographystyle{unsrt}
\bibliography{../../thesis/econophysics}
\end{document}
