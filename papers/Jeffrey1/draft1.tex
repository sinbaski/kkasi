\documentclass{article}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage[bookmarks=true]{hyperref}
\usepackage{bookmark}
\usepackage{graphicx}
\usepackage{xcolor}

\input{../../physics_common}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\theoremstyle{remark}
\newtheorem{remark}{Remark}

\title{Importance Sampling}
\author{Xie Xiaolei}
\date{\today}

\begin{document}
\maketitle
\section{Introduction}
We consider the model
\begin{eqnarray*}
V_n &=& A_n V_{n-1} + B_n\\
\end{eqnarray*}
Use the following notations
\begin{eqnarray*}
X_n &=& {
        A_n A_{n-1} \cdots A_1 \tilde V_0
        \over
        |A_n A_{n-1} \cdots A_1 \tilde V_0|
        } \\
S_n &=& \log |A_n \cdots A_1 \tilde V_0| \\
\xi_n &=& S_n - S_{n-1} = \log\frac{|A_n \cdots A_1 \tilde V_0|}{|A_{n-1}
  \cdots A_1 \tilde V_0|} \\
&=& \log\left| A_n \frac{A_{n-1} \cdots A_1 \tilde V_0}
    {|A_{n-1} \cdots A_1 \tilde V_0|} \right|\\
&=& \log |A_n X_{n-1}|
\end{eqnarray*}
The pair $(X_n, S_n)$ is a Markov additive process with transition
kernel $P$. Assume conditions (M) and (A) of Kesten \cite{Kesten1973}:
\begin{enumerate}
  \item $\P(A > 0) = 1$, $\P(B \geq 0) = 1$, $\P(B = 0) < 1$.
   
\item
  \begin{enumerate}
  \item The top Lyapunov exponent is negative, i.e.
    \begin{equation}
      \label{eq:neg_top_Lyapunov}
      \inf_{n \geq 1} \E \log \|A_n \cdots A_1\| < 0    
    \end{equation}
  \item $\exists \xi > 0$ such that $\lambda(\xi) = 1$, where
    $$
    \lambda(\xi) := \inf_{n \geq 1} (\E \|A_n \cdots A_1\|^\xi)^{1/n}
    $$
    \item $\exists \epsilon > 0$ such that $\E \|A\|^{(1 + \epsilon)\xi} <
      \infty$ and $\E |B|^{(1 + \epsilon)\xi} < \infty$.
  \end{enumerate}
  \item The additive subgroup of $\mathbb R$ generated by
    \[
    \{\log \rho(\pi): \pi = \prod_{i=1}^n A_i \text{for some n and
      iid. } A_i\}.
    \]
    is dense in $\mathbb R$. Here $\rho(\pi)$ denotes the largest
    singular value of $\pi$.
\end{enumerate}

\section{Consistency}\label{sec:consistency}
By the law of large numbers
\begin{eqnarray*}
  && \P(|V| > u) \\
  &=& \lim_{n \to \infty} {1 \over n} \sum_{i=0}^n \1{|V_i| > u}
\end{eqnarray*}
Define
\[
R_n := \inf\{0 \leq i \leq n: V_i \in \mathcal C\}
\]
and
\[
K_i := \inf\{k \geq 1: k > K_{i-1}, V_k \in \mathcal C, K_0 = 0\}
\]
Then one can write
\begin{eqnarray*}
  && \lim_{n \to \infty} {1 \over n} \sum_{i=1}^n \1{|V_i| > u} \\
  &=& \lim_{n \to \infty} {1 \over n} \left[
    \sum_{i=0}^{K_{R_n}-1} \1{|V_i| > u} + \sum_{i=K_{R_n}}^n \1{|V_i| > u}
\right]
\end{eqnarray*}
For the 2nd term, by a Borel-Cantelli argument, it maybe shown
\[
\lim_{n \to \infty} {1 \over n}\sum_{i=K_{R_n}}^n \1{|V_i| > u} = 0
\]
For the 1st term,
\begin{eqnarray*}
&& \lim_{n \to \infty} {1 \over n} \sum_{i=0}^{K_{R_n}-1} \1{|V_i| >
  u}  \\
&=& \lim_{n \to \infty} {R_n \over n} {1 \over R_n} \sum_{i=1}^{R_n}
\sum_{j=K_{i-1}}^{K_i-1}\1{|V_i| > u} \\
&=& \pi(\mathcal C) \E_\gamma N_u
\end{eqnarray*}
where the law of large numbers of Markov chains has been used to reach
the last line. In addition, it is assumed
\begin{eqnarray*}
  V_{K_i} &\sim& \gamma \; \forall i \geq 0 \\
  \gamma(E) &=& \pi(E)/\pi(\mathcal C)\; \forall E \in \mathcal
  B(\mathcal C)
\end{eqnarray*}
Define
\begin{eqnarray*}
  T_u &=& \inf\{n \geq 1: |V_n| > u\} \\
  \tau &\overset{d}{=}& K_i - K_{i-1} \\
  N_u &:=& \sum_{i=0}^{\tau-1} \1{|V_i| > u}  \\
\end{eqnarray*}
Then $\E_\gamma N_u$ may be evaluated as
\begin{eqnarray*}
  && \E_\gamma N_u \\
  &=& \E_\gamma N_u \1{T_u < \tau} \\
  &=& \int_{\mathds S^{d-1}} \int_{\mathds R} \cdots \int_{\mathds
    S^{d-1}} \int_{\mathds R} N_u \1{T_u < \tau} \times \\
  && \prod_{i=1}^{T_u} e^{-\xi(s_i - s_{i-1}) + \lambda(\xi)}
  {r(x_{i-1}; \xi) \over r(x_{i}; \xi)}P_\xi(x_{i-1}, dx_i \times ds_i) \times \\
  && \prod_{i=T_u+1}^{\tau-1} P(x_{i-1}, dx_i \times d s_i) \\
  &=& \E_{\mathcal D} \left[
    N_u \1{T_u < \tau} e^{-\xi S_{T_u}} {r(\tilde V_0; \xi)
      \over r(x_{T_u}; \xi)}
  \right]
\end{eqnarray*}
where
\[
P_\xi(x_{i-1}, dx_i \times ds_i) = e^{\xi(s_i - s_{i-1}) -
  \lambda(\xi)} {r(x_i; \xi) \over r(x_{i-1}; \xi)} P(x_{i-1}, dx_i
\times ds_i)
\]
is the $\xi$-shifted transition kernel of the {\it Markov Additive
  process} $(X_n, S_n)$. $\xi$ is chosen such that 
\[
\lambda(\xi) = \lim_{n \to \infty} \log \left(
\E \|A_n \cdots A_1\|^\xi
\right)^{1/n} = 0
\]
$\E_{\mathcal D}$ denotes expectation taken with respect to the dual
measure defined as
\[
P_{\mathcal D} (x_i, dx_{i+1} \times ds) = \left\{
  \begin{array}{ll}
    P_\xi (x_i, dx_{i+1} \times ds) & \text{ if } i < T_u \\
    P(x_i, dx_{i+1} \times ds) & \text{ if } i \geq T_u \\
  \end{array}
\right.
\]
Because the top Lyapunov exponent is negative, it follows from a lemma
in Kesten \cite{Kesten1973} that there is a $s > 0$ such that
$\lambda(s) < 0$.

Thus we have obtained a consistent estimator
$\pi(\mathcal C)\mathcal E_u$ for $\P(|V| > u)$:
\begin{eqnarray*}
\P(|V| > u) &=& \pi(\mathcal C) \E_{\mathcal D} \mathcal E_u \\
&=& \pi(\mathcal C) \E_{\mathcal D} \left[
  N_u \1{T_u < \tau} e^{-\xi S_{T_u}} {r(\tilde V_0; \xi)
    \over r(x_{T_u}; \xi)}
\right]
\end{eqnarray*}

\section{Efficiency}\label{sec:efficiency}
\begin{lemma}
  Let $\beta \in \mathbb R$ satisfy
  \begin{enumerate}
  \item
    \begin{equation}
      \label{eq:drift_cond1}
      \E \|A\|^\beta < \infty      
    \end{equation}
  \item 
    \begin{equation}
      \label{eq:drift_cond2}
    \inf_{\alpha > 0} {\E \|A\|^{\alpha + \beta}
      \over 
      \E \|A\|^{\beta}
    } < 1
    \end{equation}
  \end{enumerate}
  then $\forall \alpha > 0$ such that $\frac{\E\|A\|^{\beta +
      \alpha}}{\E\|A\|^\beta} < 1$ , we have
  \begin{equation}
    \label{eq:drift}
    \E_\beta \left[\left.
        |V_n|^\alpha r_\beta(|\tilde V_n|; \alpha) \I_{{\mathcal C}^\complement}(V_{n-1}) \right|
      \mathcal F_{n-1} \right] \leq |V_{n-1}|^\alpha r_\beta(|\tilde
    V_{n-1}|; \alpha) \I_{{\mathcal C}^\complement}(V_{n-1})
  \end{equation}
  where $r_\beta(\cdot; \alpha)$ is the unique right eigen function of the
  operator
  \[
  P_{\beta, \alpha} f(x) = \int |\mathbf a x|^\alpha f\left(
    {\mathbf a x \over |\mathbf a x|}
  \right) d\mu_A^\beta(\mathbf a)
  \]
  where the $\beta$-shifted measure $\mu_A^\beta$ satisfies
  \[
  d\mu_A^\beta(\mathbf a) = {\|\mathbf a\|^\beta d\mu_A(\mathbf a) \over \E\|A\|^\beta}
  \]
  The set $\mathcal C = [-M_\beta(\alpha),
  M_\beta(\alpha)]$. $M_\beta(\alpha)$ is chosen with respect to the
  values of $\alpha$ and $\beta$.
\end{lemma}

\begin{proof}
  Conditions \eqref{eq:drift_cond1} and \eqref{eq:drift_cond2} imply $\E_\beta
  \|A\|^\alpha < \infty$. Then, using the results of Buraczewski and
  Collamore et al \cite{BCDZ2014}, one may conclude that an eigen
  function $r_\beta(\cdot; \alpha)$ as well as an eigen measure
  $l_\beta(\cdot; \alpha)$ exists under the $\beta$-shifted
  measure. Thus, by defining the adjoint operator under  the shifted
  measure, the right eigen function $r_\beta(x; \alpha)$ can be represented as
  \[
  r_\beta(x; \alpha) = c \int_{S_+^{d-1}} \inn{x, y}^\alpha
  dl^*_{\beta}(y; \alpha)
  \]
Now, to prove \eqref{eq:drift}, consider
  \begin{eqnarray}
    && \E_\beta \left[ |V_n|^\alpha r_\beta(\tilde V_n; \alpha) | \mathcal F_{n-1} \right]
    \nonumber \\
    &=& \E_\beta\left[\int_{S_+^{d-1}} \inn{V_n, y}^\alpha dl^*_{\beta}(y; \alpha)|
      \mathcal F_{n-1} \right]
    \nonumber \\
    &=& \E_\beta\left[\int_{S_+^{d-1}} (\inn{A_n V_{n-1}, y} + \inn{B_n,
        y})^\alpha dl^*_{\beta}(y; \alpha) | \mathcal F_{n-1} \right]
    \label{eq:drift_proof_1}
  \end{eqnarray}
  \begin{enumerate}
  \item if $\alpha \leq 1$, by subadditivity we have
    \begin{eqnarray*}
      &&\E_\beta\left[\int_{S_+^{d-1}} (\inn{A_n V_{n-1}, y} + \inn{B_n,
          y})^\alpha dl^*_{\beta}(y; \alpha) | \mathcal F_{n-1} \right]\\
      &\leq& \E_\beta\left[\int_{S_+^{d-1}} \inn{A_n V_{n-1}, y}^\alpha
        dl^*_{\beta}(y; \alpha) | \mathcal F_{n-1} \right]
      + \E_\beta\left[\int_{S_+^{d-1}} \inn{B_n, y}^\alpha dl^*_{\beta}(y; \alpha) |
        \mathcal F_{n-1} \right] \\
      &=& \E_\beta\left[|V_{n-1}|^\alpha |A_n \tilde V_{n-1}|^\alpha\int_{S_+^{d-1}}
        \inn{ {A_n \tilde V_{n-1} \over |A_n \tilde V_{n-1}|}, y}^\alpha
        dl^*_{\beta}(y; \alpha) | \mathcal F_{n-1} \right]  + \E r_\beta(B_n; \alpha)\\
      &=& |V_{n-1}|^\alpha  \int |\mathbf a \tilde V_{n-1}|^\alpha
      r_\beta\left({\mathbf a \tilde V_{n-1} \over |\mathbf a \tilde V_{n-1}|}; \alpha\right)
      d\mu_A^\beta (\mathbf a) + \E r_\beta(B_n; \alpha) \\
      &=& |V_{n-1}|^\alpha (P_{\beta, \alpha} r_{\beta})(\tilde V_{n-1}; \alpha) +
      \E_\beta r_\beta(B_n; \alpha) \\
      &=& |V_{n-1}|^\alpha r_\beta(\tilde V_{n-1}; \alpha) \lambda_\beta(\alpha)
      \left\{
        1 + 
        {\E_\beta r_\beta(B_n; \alpha) \over |V_{n-1}|^\alpha \lambda_\beta(\alpha) r_\beta(\tilde V_{n-1}; \alpha)}
         \right\} \\
    \end{eqnarray*}
    When $V_{n-1} \in \mathcal C^\complement$, $|V_{n-1}| > M_\beta(\alpha)$.
    Moreover, $\E_\beta|B_n|^\alpha < \infty$ by assumption while
    $r_\beta(\tilde B_n; \alpha) < \infty$, $r_\beta(\tilde V_{n-1}; \alpha) < \infty$
    according to Buraczewski and Collamore \cite{BCDZ2014}. Thus
    \begin{eqnarray*}
      && \E_\beta \left[ \left.
          |V_n|^\alpha r_\beta(\tilde V_n; \alpha) \I_{\mathcal C^\complement}(V_{n-1})
        \right| \mathcal F_{n-1}
      \right] \\
      &\leq&
      |V_{n-1}|^\alpha r_\beta(\tilde V_{n-1}; \alpha) \lambda_\beta(\alpha)
      \left[
        1 + 
        {\E_\beta r_\beta(B_n; \alpha) \over M^\alpha \lambda_\beta(\alpha) r_\beta(\tilde V_{n-1}; \alpha)}
      \right]
      \I_{\mathcal C^\complement}(V_{n-1})
    \end{eqnarray*}
    Also note
    \begin{equation*}
      \lambda_\beta(\alpha) \leq \E_\beta \|A_1\|^\alpha = {
        \E \|A_1\|^{\alpha + \beta}
        \over
        \E \|A_1\|^{\beta}
      }
    \end{equation*}
    Hence by assumption \eqref{eq:drift_cond2}, $\lambda_\beta(\alpha)
    < 1$. Therefore, $M_\beta(\alpha)$ can be chosen sufficiently large so that
    \begin{eqnarray}
      \lambda_\beta(\alpha) \left[
        1 +  
        {\E_\beta r_\beta(B_n; \alpha) \over M_\beta(\alpha)^\alpha
          \lambda_\beta(\alpha) r_\beta(\tilde V_{n-1}; \alpha)}
        \right] &<& 1 \label{eq:cond_on_M}
    \end{eqnarray}
    From \eqref{eq:cond_on_M} it follows
    \begin{equation}
      \label{eq:C_set}
      M_\beta(\alpha) > \left\{
        \bar r_{\beta, \alpha}\E_\beta |B|^\alpha
          \over
          [1 - \lambda_\beta(\alpha)] \underline r_{\beta, \alpha}
        \right\}^{1/\alpha}
    \end{equation}
    where
    \begin{eqnarray*}
      \bar r_{\beta, \alpha} &=& \sup_{x \in \mathbb S^{d-1}}
      r_\beta(x; \alpha) \\
      \underline r_{\beta, \alpha} &=& \inf_{x \in \mathbb S^{d-1}}
      r_\beta(x; \alpha)
    \end{eqnarray*}
    Here we note $\E_\beta |B|^\alpha = \E |B|^\alpha$
    since the distribution of $B$ is left the same when
    changing to the shifted measure.

    \item If $\alpha > 1$, applying Minkowski's inequality to the RHS
      of \eqref{eq:drift_proof_1} and using similar arguments as in
      the $\alpha \leq 1$ case gives
      \begin{eqnarray*}
        && \E_\beta \left[ \left.
          |V_n|^\alpha r_\beta(\tilde V_{n}; \alpha)
          \I_{\mathcal C^\complement}(V_{n-1})
          \right| \mathcal F_{n-1}
        \right] \\
        &\leq&
        |V_{n-1}|^\alpha r_\beta(\tilde V_{n-1}; \alpha)
        \lambda_\beta(\alpha) \left\{
          1 + \left[
            {
              \E r_\beta(B; \alpha)
              \over
              M_\beta(\alpha)^\alpha
              r_\beta(\tilde V_{n-1}; \alpha)
              \lambda_\beta(\alpha)
            }
          \right]^{1/\alpha}
          \right\}^\alpha
          \I_{\mathcal C^\complement}(V_{n-1})
      \end{eqnarray*}
      and correspondingly
      \begin{equation*}
        M_\beta(\alpha) > \left[
          {
            \bar r_{\beta,\alpha} \E |B|^\alpha
            \over
            \underline r_{\beta, \alpha}
          }
        \right]^{1/\alpha} {
          1 \over
          1 - \lambda_\beta(\alpha)^{1/\alpha}
        }
      \end{equation*}
  \end{enumerate}    
\end{proof}

\begin{remark}
  Iterating \eqref{eq:drift} yields
  \[
  \E_\beta \left[
    |V_n|^\alpha r_\beta(|\tilde V_n|; \alpha)
    \prod_{i=1}^{n-1}\I_{{\mathcal C}^\complement}(V_i)\right]
  \leq \rho_\beta(\alpha)^{n-1} |V_1|^\alpha r_\beta(|\tilde V_1|; \alpha) \I_{{\mathcal C}^\complement}(V_1)
  \]
  Then it follows
  \[
  \E_\beta \left[
    |V_n|^\alpha r_\beta(|\tilde V_n|; \alpha) \prod_{i=1}^{n}\I_{{\mathcal C}^\complement}(V_i)\right]
  \leq \rho_\beta(\alpha)^{n-1} |V_1|^\alpha r_\beta(|\tilde V_1|; \alpha) \I_{{\mathcal C}^\complement}(V_1)
  \]
  But $\prod_{i=1}^{n}\I_{{\mathcal C}^\complement}(V_i)$ implies $\tau > n$, and in this
  case $|V_n| > M$, where
  \[
  M = \left[
    \E_\beta (|B|^\alpha r_\beta(\tilde B; \alpha)) 
    \over
    (1 - \lambda(\alpha)) r_\beta(\tilde v; \alpha)
  \right]^{1/\alpha}
  \]
  Hence
  \begin{eqnarray}
    \E_\beta \left[
      M^\alpha \inf_{|\tilde V_n|} r_\beta(|\tilde V_n|; \alpha) \1{\tau > n}\right]
    &\leq& \rho_\beta(\alpha)^{n-1} |V_1|^\alpha r_\beta(|\tilde V_1|;
    \alpha) \I_{{\mathcal C}^\complement}(V_1) \nonumber \\
    \P_\beta(\tau > n) &\leq& K \rho_\beta(\alpha)^{n-1} \\
    &=& K [b \lambda_{\beta}(\alpha)]^{n-1} \label{eq:ret_time}
  \end{eqnarray}
  for some constant $K$ and some $b > 1$.
\end{remark}

% \begin{lemma}
%   \label{lemma:A_norm_a.s}
%   Assume $\beta > 0$ and $\E \|A\|^{\beta} < \infty$. Then
%   for all $0 < \alpha < \beta$,
%   $\|A\|^{\alpha} < \infty$ almost surely.
% \end{lemma}
% \begin{proof}
%   We need to show
%   \begin{eqnarray*}
%     \P\left(
%       \bigcup_{N=1}^\infty \bigcap_{k=N}^\infty
%     \left\{
%     \|A\|^\alpha \leq k
%     \right\}
%     \right) &=& 1
%   \end{eqnarray*}
%   By Borel-Cantelli lemma, it suffices to show
%   \begin{equation*}
%     \sum_{k=1}^\infty \P(\|A\|^\alpha > k) < \infty
%   \end{equation*}
%   By Markov's inequality
%   \begin{eqnarray*}
%     && \sum_{k=1}^\infty \P(\|A\|^\alpha > k)
%        \leq
%        \sum_{k=1}^\infty
%        {
%        \E \|A\|^{p\alpha}
%        \over
%        k^p
%        }
%   \end{eqnarray*}
%   for some $1 < p < \beta/\alpha$. Since
%   $\E \|A\|^{p\alpha} < \E \|A\|^{\beta} < \infty$,
%   it follows
%   \begin{equation*}
%     \sum_{k=1}^\infty
%     {
%       \E \|A\|^{p\alpha}
%       \over
%       k^p
%     }
%     \leq
%     \sum_{k=1}^\infty
%     {
%       C
%       \over
%       k^p
%     } < \infty
%   \end{equation*}
%   for some constant $C$.
% \end{proof}

% \begin{lemma}
%   \label{lemma:Pi_n_to_alpha_a.s.}
%   Assume $\lambda(\beta) < \infty$, then for all $n \geq 1$, and for
%   all $0 < \alpha < \beta$,
%   \begin{equation*}
%     \|A_{n} \cdots A_{1}\|^\alpha < \infty \text{ a.s.}
%   \end{equation*}
% \end{lemma}
% \begin{proof}
%   By Borel-Cantelli lemma, it suffices to show
%   \begin{eqnarray*}
%     \sum_{k=1}^\infty \P(\|A_{n} \cdots A_{1}\|^\alpha > k) &<& \infty
%     \\
%     \sum_{k=1}^\infty \P(\|A_{n} \cdots A_{1}\|^{p\alpha} > k^p) &<& \infty    
%   \end{eqnarray*}
%   for some $1 < p < \beta/\alpha$. Since
%   \begin{equation*}
%     \lim_{l \to \infty} {1 \over l} \log \E \|A_l \cdots A_1\|^\alpha
%     = \lambda(\alpha)
%   \end{equation*}
%   and $\lambda(\alpha) < \lambda(\beta) < \infty$, we have, when $l$
%   is sufficiently large and for all $a > 1$,
%   \begin{equation*}
%     \E \|A_l \cdots A_1\|^\alpha \leq [a \lambda(\alpha)]^l
%   \end{equation*}
%   Thus by choosing $N$ sufficiently large we have
%   \begin{eqnarray*}
%     && \sum_{k=1}^\infty \P(\|A_{n} \cdots A_{1}\|^{p\alpha} > k^p) \\
%     &\leq& \sum_{k=1}^{\infty} {
%            \E \|A_{n} \cdots A_{1}\|^{p\alpha}
%            \over
%            k^p
%            } \\
%     &\leq& (\E \|A_1\|^{p\alpha})^{n}\1{n \leq N}
%            \sum_{k=1}^\infty {1 \over k^p} +
%            [a \lambda(p\alpha)]^{n}\1{n > N}
%            \sum_{k=1}^\infty {1 \over k^p}
%            < \infty
%   \end{eqnarray*}
% \end{proof}

% \begin{lemma}
%   Assume $\lambda(\beta) < \infty$, then for all $n \geq 1$, and for
%   all $0 < \alpha < \beta$,
%   \begin{equation*}
%     \|A_{T_u} \cdots A_{n+1}\|^\alpha \1{n \leq T_u < \tau}
%     < \infty \text{ a.s.}
%   \end{equation*}
% \end{lemma}
% \begin{proof}
%   Throughout this proof, we use $c, c_1, c_2, \dots$ to denote
%   constants whose values have no significance. Each of them may stand
%   for one or more values depending on the context.

%   By Borel-Cantelli lemma, it suffices to show
%   \begin{equation*}
%     \sum_{k=1}^\infty
%     \P \left(
%       \|A_{T_u} \cdots A_{n+1}\|^\alpha
%       \1{n \leq T_u < \tau} > k
%     \right) < \infty
%   \end{equation*}
%   LHS of the above inequality can be re-written
%   \begin{eqnarray*}
%     &&
%        \sum_{k=1}^\infty
%        \P \left(
%        \|A_{T_u} \cdots A_{n+1}\|^\alpha
%        \1{n \leq T_u < \tau} > k
%        \right) \\
%     &=& \sum_{k=1}^\infty \sum_{l=n}^\infty
%         \P \left(
%         \|A_l \cdots A_{n+1}\|^\alpha
%         \1{T_u = l}
%         \1{\tau > l} > k
%         \right) \\
%     &\leq& \sum_{k=1}^\infty \sum_{l=n}^\infty
%            {
%            \E (\|A_l \cdots A_{n+1}\|^{p \alpha}
%            \1{T_u = l} \1{\tau > l})
%            \over
%            k^p
%            }
%   \end{eqnarray*}
%   for some $1 < p < \beta/\alpha$.
%   As shown in lemma \ref{lemma:Pi_n_to_alpha_a.s.},
%   $\|A_l \cdots A_{n+1}\|^{p \alpha} < \infty$ a.s. Hence
%   \[
%   \E (\|A_l \cdots A_{n+1}\|^{p \alpha}
%   \1{T_u = l} \1{\tau > l}) \leq c \P(\tau > l)
%   \]
%   Applying \eqref{eq:ret_time} gives
%   \[
%   \P(\tau > l) \leq c_1 [a \lambda(\theta)]^{l-1}
%   \]
%   for some $0 < \theta < \xi$ and $a > 1$ such that $a \lambda(\theta) <
%   1$. Thus it follows
%   \begin{eqnarray*}
%     && \sum_{k=1}^\infty \sum_{l=n}^\infty
%            {
%            \E (\|A_l \cdots A_{n+1}\|^{p \alpha}
%            \1{T_u = l} \1{\tau > l})
%            \over
%            k^p
%            } \\
%     &\leq& \sum_{k=1}^\infty {c \over k^p}
%            \sum_{l=n}^\infty [a \lambda(\theta)]^{l-1} \\
%     &=& c {
%         [a \lambda(\theta)]^{n-1}
%         \over
%         1 - a \lambda(\theta)
%         }
%         \sum_{k=1}^\infty {1 \over k^p}
%         < \infty
%   \end{eqnarray*}
% \end{proof}

\begin{theorem}
  The estimator $\mathcal E_u$ has bounded relative error, i.e.
  \begin{equation*}
    \limsup_{u \to \infty} {\var(\mathcal E_u) \over [\P(|V| > u)]^2} < \infty
  \end{equation*}
\end{theorem}
\begin{proof}
  The assertion is equivalent to
  \[
  \limsup_{u \to \infty} {\E_{\mathcal D} \mathcal E_u^2 \over [\P(|V|
    > u)]^2} < \infty
  \]
  By Kesten's theorem \cite{Kesten1973}, $\P(|V| > u) \sim C
  u^{-\xi}$. Hence, to prove the assertion, one needs to check
  $\limsup_{u \to \infty} u^{2\xi}\E_{\mathcal D} \mathcal E_u^2 <
  \infty$, i.e.
  \[
  \limsup_{u \to \infty} \E_{\mathcal D}  \left[u^{2\xi}
    N_u^2 \1{T_u < \tau} e^{-2\xi S_{T_u}} {r^2(\tilde V_0; \xi)
      \over r^2(x_{T_u}; \xi)}\right] < \infty
 \]
 Using the fact $|V_{T_u}| > u$, and that $r(\cdot; \xi)$ is bounded
 from above and below, it suffices to show
 \begin{eqnarray}
   f(\xi) &=& \limsup_{u \to \infty} \E_{\mathcal D} \left[
     \left|
       \sum_{n=0}^{T_u}
       \frac{
         N_u^{1/\xi} A_{T_u} \cdots A_{n+1} B_n 
       }{
         |A_{T_u} \cdots A_1 V_0|
       }
       \1{T_u < \tau}
     \right|^{2 \xi}
   \right] < \infty \label{eq:efficiency_target}
 \end{eqnarray}
  In the rest of the proof, we write $c, c_1, c_2, \dots$ for
  constants whose values have no importance and depend on the
  context. Since $\xi > 1$, Minkowski's inequality gives
    \begin{eqnarray}
      f(\xi) &\leq& \limsup_{u \to \infty}
      \left\{
        \sum_{n=0}^{\infty}
        \left[
          \E_{\mathcal D} \left|
            N_u^{1/\xi}
            \frac{
              A_{T_u} \cdots A_{n+1} B_n 
            }{
              |A_{T_u} \cdots A_1 V_0|
            }
            \1{n \leq T_u < \tau}
          \right|^{2 \xi}
        \right]^{1/2\xi}
      \right\}^{2\xi} \nonumber \\
      f(\xi)^{1/2\xi}
      &\leq& \limsup_{u \to \infty}
      \sum_{n=0}^\infty
      \left(
        \E_D {
          |B_n|^{2\xi}
          \over
          |V_0|^{2\xi}
        }
      \right)^{1/2\xi}
      \left(
        \E_D {
          \|A_{T_u} \cdots A_{n+1}\|^{2\xi}
          \1{n \leq T_u < \tau}
          N_u^2
          \over
          \|A_{T_u} \cdots A_{n+1}\|^{2\xi}
          |A_n \cdots A_1 X_0|^{2\xi}
        }
      \right)^{1/2\xi} \\
      &\leq&
      c \limsup_{u \to \infty}
      \sum_{n=0}^\infty
      \left(
        \E_D |A_n \cdots A_1 X_0|^{-2\xi}
        N_u^2
        \1{n \leq T_u < \tau}        
      \right)^{1/2\xi} \\
      &\leq&
      c \limsup_{u \to \infty}
      \sum_{n=0}^\infty
      \E \left(
        |A_n \cdots A_1 X_0|^{-\xi}
        N_u^2
        \1{n \leq T_u < \tau}        
      \right)^{1/2\xi} \label{eq:split_point}
    \end{eqnarray}
    
  \begin{enumerate}
  \item If $\lambda(-\xi) < \infty$, we assume
    \begin{equation}
      \label{eq:cond1}
      \lambda(-\xi)
      \inf_{\alpha \in \mathbb R} \lambda_{-\xi}(\alpha) < 1
    \end{equation}
    Changing to the $-\xi$-shifted measure, we obtain
    \begin{eqnarray}
      &&
      c \sum_{n=0}^\infty
      \E \left(
        |A_n \cdots A_1 X_0|^{-\xi}
        N_u^2
        \1{n \leq T_u < \tau}        
      \right)^{1/2\xi} \\
      &\leq&
      c \sum_{n=0}^\infty
      \E_{-\xi} (N_u^2 \1{n \leq T_u < \tau})
      \lambda(-\xi)^n \\
      &\leq&
      c \sum_{n=0}^\infty
      \E_{-\xi} (\tau^2 \1{n < \tau})
      \lambda(-\xi)^n \\
      &\leq&
      c \sum_{n=0}^\infty
      \sum_{l=n+1}^\infty
      l^2 \P_{-\xi}(\tau > l-1)
      \lambda(-\xi)^n
    \end{eqnarray}
    Applying \eqref{eq:ret_time} with $\beta = -\xi$ gives, for some
    $a > 0$, $\P_{-\xi}(\tau > l-1) \leq a [\delta \lambda_{-\xi}(\alpha)]^{l-2}$
    for all $\delta > 1$ and $\delta \lambda_{-\xi}(\alpha) < 1$
    provided that $M$ is chosen sufficiently large. Thus the RHS of the
    above inequality is bounded by
    \begin{eqnarray*}
      c \sum_{n=0}^\infty
      \lambda(-\xi)^n
      \sum_{l=n+1}^\infty
      l^2 [\delta \lambda_{-\xi}(\alpha)]^{l-2}
    \end{eqnarray*}
    The second sum in the above evaluates to a finite sum of terms
    each having the form $c n^k [\delta
    \lambda_{-\xi}(\alpha)]^n$. Hence to show $f(\xi) < \infty$, it
    suffices to show
    \begin{equation*}
      \sum_{n=0}^\infty
      n^k [\delta \lambda(-\xi) \lambda_{-\xi}(\alpha)]^n < \infty
    \end{equation*}
    Under assumption \eqref{eq:cond1} the above inequality is
    obviously true.
  \item If $\lambda(-\xi) = \infty$, we assume $\lambda(h\xi) <
    \infty$ and $\E(|B|/\|A\|)^{h\xi} <  \infty$. Since
    \[
    V_n = \sum_{i=0}^n A_n \cdots A_{i+1} B_i
    \]
    it follows
    \begin{eqnarray*}
      |V_n|\1{\tau > n} &\leq&
      \sum_{i=0}^{n} \|A_n \cdots A_{i+1}\| |B_i| \\
      \|A_n \cdots A_1\|^{-1} \1{\tau > n}
      &\leq& |V_n|^{-1} \1{\tau > n}
      \left[
        |B_0| + \sum_{i=1}^n {
          \|A_n \cdots A_{i+1}\|
          \over
          \|A_n \cdots A_{1}\|
        } |B_i|
      \right] \\
      &\leq& {1 \over M}
      \left[
        |B_0| + \sum_{i=1}^n {
          \|A_n \cdots A_{i+1}\|
          \over
          \|A_n \cdots A_{1}\|
        } |B_i| \1{\tau > n}
      \right]
    \end{eqnarray*}
    Note
    \[
    \|A_n \dots A_{i+1} A_i \cdots A_1\| \geq
    C^{-1} \|A_n \cdots A_{i+1}\|
    \|A_i \cdots A_{1}\|
    \]
    for some $C > 1$. We have
    \begin{equation}
      \label{eq:lower_bound}
      \|A_n \cdots A_1\|^{-1} \1{\tau > n}
      \leq
      {1 \over M} \left[
        |B_0| + \sum_{i=1}^n {
          C |B_i|
          \over
          \|A_i \cdots A_1\|
        }  \1{\tau > n}
      \right]
    \end{equation}
    Let
    \[
    J_k = \|A_k \cdots A_1\|^{-1} \1{\tau > n}
    \]
    We obtain
    \begin{eqnarray*}
      \left(
        \E J_n^\zeta
      \right)^{1/\zeta} &\leq& \left[
        \E \left(
          {|B_0| \over M}
          + {C \over M} \sum_{i=1}^n |B_i| J_i
        \right)^\zeta
        \right]^{1/\zeta}
    \end{eqnarray*}
    Using Minkowski's inequality and the independence of $B_i$ and
    $A_i, \dots, A_1$ the above yields
    \begin{eqnarray}
      (\E J_n^\zeta)^{1/\zeta} &\leq&
      {|B_0| \over M} + {C \over M}
      \sum_{i=1}^n
      (\E |B_i|^\zeta)^{1/\zeta}
      (\E J_i^\zeta)^{1/\zeta}
      \label{eq:neg_pow_ub} \\
      &=& h_1 + h_2 \sum_{i=1}^{n-1} (\E J_i^\zeta)^{1/\zeta}
      \nonumber
    \end{eqnarray}
    where
    \begin{eqnarray*}
      h_1 &=& {|B_0| \over M} \\
      h_2 &=& {C \over M} (\E |B_1|^\zeta)^{1/\zeta}
    \end{eqnarray*}
    Since
    \begin{eqnarray*}
      V_1 &=& A_1 V_0 + B_1 \\
      |V_1| &\leq& \|A_1\| |V_0| + |B_1| \\
      \end{eqnarray*}
      and by assumption $\E (|B|/\|A\|)^\zeta < \infty$, we have
      \begin{eqnarray}
        (\E J_1^\zeta)^{1/\zeta} &=&
        \left[
        \E (\|A_1\|^{-\zeta}\1{\tau > n})
      \right]^{1/\zeta} \nonumber \\
      &\leq&
      {|V_0|\over M} \E \left[\left(
        1 + {|B_1| \over |V_0| \|A_1\|}
      \right)^\zeta
      \1{\tau > n}\right]^{1/\zeta}< \infty
    \label{eq:J_1}
    \end{eqnarray}
    Let
    \[
    y_1(\zeta) = 
    {|V_0|\over M} \E \left[\left(
        1 + {|B_1| \over |V_0| \|A_1\|}
      \right)^\zeta \1{\tau > n}\right]^{1/\zeta}
    \]
    and
    \begin{equation}
      \label{eq:y_n}
      y_n(\zeta) = h_1 + h_2 \sum_{i=1}^{n-1} y_i(\zeta)
    \end{equation}
    Then \eqref{eq:neg_pow_ub}, \eqref{eq:y_n} and \eqref{eq:J_1}
    yield
    \begin{equation}
      \label{eq:J_n_2}
      (\E J_n^\zeta)^{1/\zeta} \leq y_n(\zeta)
    \end{equation}
    Meanwhile \eqref{eq:y_n} gives, $\forall n \geq 1$,
    \begin{equation}
      \label{eq:y_n_2}
      y_n(\zeta) = {y_1(\zeta) \over (1 - h_2)^{n-1}}
    \end{equation}

    % Using Minkowski's inequality on RHS of
    % \eqref{eq:efficiency_target} leads to
    %   \begin{eqnarray*}
    %     f(\xi) &\leq& \limsup_{u \to \infty}
    %     \left\{
    %       \sum_{n=0}^{\infty}
    %       \left[
    %         \E_{\mathcal D} \left|
    %           N_u^{1/\xi}
    %           \frac{
    %             A_{T_u} \cdots A_{n+1} B_n 
    %           }{
    %             |A_{T_u} \cdots A_1 V_0|
    %           }
    %           \1{n \leq T_u < \tau}
    %         \right|^{2 \xi}
    %       \right]^{1/2\xi}
    %     \right\}^{2\xi} \\
    %     &\leq& c \limsup_{u \to \infty}
    %     \left\{
    %       \sum_{n=0}^{\infty}
    %       \left[
    %         \E \left(
    %           N_u^2
    %           \frac{
    %             |A_{T_u} \cdots A_{n+1} B_n|^{2\xi}
    %           }{
    %             |A_{T_u} \cdots A_1 V_0|^\xi
    %           }
    %           \1{n \leq T_u < \tau}
    %         \right)
    %       \right]^{1/2\xi}
    %     \right\}^{2\xi}
    %   \end{eqnarray*}
      % By H\"older's inequality we have
      % \begin{eqnarray*}
      %   &&
      %   \E \left(
      %     N_u^2
      %     \frac{
      %       |A_{T_u} \cdots A_{n+1} B_n|^{2\xi}
      %     }{
      %       |A_{T_u} \cdots A_1 V_0|^\xi
      %     }
      %     \1{n \leq T_u < \tau}
      %   \right) \\
      %   &\leq&
      %   (\E N_u^{2r}\1{n \leq T_u < \tau})^{1/r}
      %   \left(
      %     \E {
      %       |A_{T_u} \cdots A_{n+1} B_n|^{2s \xi}
      %       \over
      %       |A_{T_u} \cdots A_1 V_0|^{s \xi}
      %     } \1{n \leq T_u < \tau}
      %   \right)^{1/s} \times \\
      %   &&
      %   (\E \1{n \leq T_u < \tau})^{1/r} \\
        % &\leq&
        % c
        % (\E N_u^{2r}\1{n \leq T_u < \tau})^{1/r}
        % \left(
        %   \E {
        %     \|A_{T_u} \cdots A_{n+1} \|^{2s\xi} |B_n|^{2s \xi}
        %     \over
        %     \|A_{T_u} \cdots A_{n+1} \|^{s\xi} \|A_n\|^{s\xi}
        %     \|A_{n-1} \cdots A_1\|^{s\xi} |V_0|^{s \xi}
        %   } \1{n \leq T_u < \tau}
        % \right)^{1/s} \times \\
        % &&
        % (\E \1{n \leq T_u < \tau})^{1/r} \\
        % &\leq&
        % c
        % (\E N_u^{2r}\1{n \leq T_u < \tau})^{1/r}
        % \left(
        %   \E {
        %     \|A_{T_u} \cdots A_{n+1} \|^{s\xi}
        %     \over
        %     \|A_{n-1} \cdots A_1\|^{s\xi}
        %  }
        %  \1{n \leq T_u < \tau}
        %   \right)^{1/s}         
        %   \left(
        %   \E {
        %     |B_n|^{2s\xi}
        %     \over
        %     |A_n|^{2\xi}
        %   }
        % \right)^{1/s} \times \\
        % &&
        % (\E \1{n \leq T_u < \tau})^{1/r}
      % \end{eqnarray*}
      % where $r$ and $s$ satisify $1/s + 2/r = 1$.
      % The last line follows from the second last using the fact that
      % each $A_n$ and $B_n$ is independent.

      % Observe
      % \begin{eqnarray*}
      %   &&
      %   \E
      %   \left(
      %     {
      %       \|A_{T_u} \cdots A_{n+1} \|^{s\xi}
      %       \over
      %       \|A_{n-1} \cdots A_1\|^{s\xi}
      %     }
      %     \1{n \leq T_u < \tau}
      %   \right) \\
      %   &=&
      %   \sum_{l=n}^\infty
      %   \E
      %   \left(
      %     {
      %       \|A_{l} \cdots A_{n+1} \|^{s\xi}
      %       \over
      %       \|A_{n-1} \cdots A_1\|^{s\xi}
      %     }
      %   \1{\tau > l} \1{T_u = l}
      % \right)
      % \end{eqnarray*}
      % Becasue $\|A_l \cdots A_{n+1}\|$ and
      % $\|A_{n-1} \cdots A_1\|$ are independent of each other,
      % we have
      % \begin{eqnarray*}
      %   &&
      %   \sum_{l=n}^\infty
      %   \E
      %   \left(
      %     {
      %       \|A_{l} \cdots A_{n+1} \|^{s\xi}
      %       \over
      %       \|A_{n-1} \cdots A_1\|^{s\xi}
      %     }
      %     \1{\tau > l} \1{T_u = l}
      %   \right) \\
      %   &\leq&
      %   \sum_{l=n}^\infty
      %   \E (\|A_l \cdots A_{n+1}\|^{s \xi}) \1{\tau > l}
      %   \E (\|A_{n-1} \cdots A_{1}\|^{- s\xi}) \1{\tau > l} \\
      %   &\leq&
      %   c \sum_{l=n}^\infty
      %   \E (|A_l \cdots A_{n+1} X_{n}|^{s \xi}\1{\tau > l})
      %   \E (\|A_{n-1} \cdots A_{1}\|^{- s\xi} \1{\tau > l})
      % \end{eqnarray*}
      % Using \eqref{eq:J_n_2} and \eqref{eq:y_n_2}, RHS of the above
      % inequality is bounded by
      % \begin{eqnarray*}
      %   c \sum_{l=n}^\infty
      %   \left[{y_1 \over (1 - h_2)^{n-2}}\right]^{s\xi}
      %   \E (|A_l \cdots A_{n+1} X_{n}|^{s \xi}\1{\tau > l})
      % \end{eqnarray*}
      % By changing to the $s\xi$-shifted measure we get
      % \begin{eqnarray*}
      %   &&
      %   c \sum_{l=n}^\infty
      %   \left[{y_1 \over (1 - h_2)^{n-2}}\right]^{s\xi}
      %   \E (|A_l \cdots A_{n+1} X_{n}|^{s \xi}\1{\tau > l}) \\
      %   &\leq&
      %   c \sum_{l=n}^\infty
      %   \left[{y_1 \over (1 - h_2)^{n-2}}\right]^{s\xi}        
      %   \E_{s\xi} \left[
      %     {r(X_n) \over r(X_l)}
      %     \1{\tau > l}
      %   \right]
      %   \lambda(s\xi)^{l-n}
      % \end{eqnarray*}
    Now from \eqref{eq:split_point} it follows by H\"older's inequality
    \begin{eqnarray*}
      f(\xi)^{1/2\xi}
      &\leq&
      c \sum_{n=0}^\infty
      (\E N_u^{2r})^{1/r}
      (\E |A_n \cdots A_1 X_0|^{-s\xi}\1{n \leq T_u < \tau})^{1/s} \\
      &\leq&
      c \sum_{n=0}^\infty
      (\E\tau^{2r})^{1/r}
      (\E |A_n \cdots A_1 X_0|^{-s\xi}\1{n \leq T_u < \tau})^{1/s}
    \end{eqnarray*}
    where $1/r + 1/s = 1$. Obviously
    \begin{eqnarray*}
      \E \tau^{2r}
      &\leq&
      \sum_{l=2}^\infty l^{2r} \P(\tau > l-1)
    \end{eqnarray*}
    Applying \eqref{eq:ret_time} with $\beta = 0$ gives $\P(\tau >
    l-1) \leq a [\delta \lambda(\alpha)]^{l-2}$ for some $a > 0$ and
    all $\delta > 1$ such that $\delta \lambda(\alpha) < 1$. So we
    have
    \begin{eqnarray*}
      \sum_{l=2}^\infty l^{2r} \P(\tau > l-1) < \infty
    \end{eqnarray*}
    for any finite $r$. Thus it remains to show
    \begin{equation}
      \label{eq:sum_neg_pow}
      \sum_{n=0}^\infty
      (\E |A_n \cdots A_1 X_0|^{-s\xi}\1{n \leq T_u < \tau})^{1/s}
      < \infty
    \end{equation}
    Since for each $n$, it has been shown
    \begin{equation*}
      \E (\|A_n \cdots A_1\|^{-s\xi}\1{n \leq T_u < \tau})
      < y_n(s\xi)^{s\xi} < \infty
    \end{equation*}
    We may choose $L_n > 0$ and $L_n \downarrow 0$ sufficiently fast that
    \begin{equation*}
      \E (
      \|A_n \cdots A_1\|^{-s\xi}
      \I_{F_n^\complement}
      \1{\tau > n} 
      ) < {1 / n^{s+\epsilon}}
    \end{equation*}
    where $\epsilon > 0$ and
    \begin{equation*}
      F_n = \bigcap_{i=1}^n \{\|A_i\| \geq L_n\}
    \end{equation*}
    Thus
    \begin{equation*}
      \sum_{n=0}^\infty
      (\E |A_n \cdots A_1 X_0|^{-s\xi}\1{n \leq T_u < \tau}
      \I_{F_n^\complement})^{1/s}
      \leq
      1 + 
      \sum_{n=1}^\infty {1 \over n^{(s + \epsilon)/s}} < \infty
    \end{equation*}
    To prove \eqref{eq:sum_neg_pow}, we still have to show
    \begin{equation}
      \label{eq:sum_on_F_n}
      \sum_{n=0}^\infty
      (\E |A_n \cdots A_1 X_0|^{-s\xi}\1{n \leq T_u < \tau}
      \I_{F_n})^{1/s} < \infty
    \end{equation}
    For each matrix $A_n$, construct a matrix $\bar A_{n, k}$, whose
    $(i,j)$-th entry is
    \begin{equation*}
      (\bar A_{n,k})_{i,j} = (A_n)_{i,j}\1{(A_n)_{ij} > L_k} +
      L_n (1 + U_{i,j})\1{(A_n)_{i,j} \leq L_k}
    \end{equation*}
    where $L_k \downarrow 0$ as $k \to \infty$; $U_{i,j}$ are
    iid. and uniformly distributed on $(0,1)$.
    % Note
    % $\bar A_{i,k}\I_{F_n} = A_{i}\I_{F_n}$ for all $1 \leq i \leq n$
    % when $k \geq n$.
    Observe
    \begin{eqnarray*}
      \|\bar A_{n,k}\|
      &=&
      \max_{|x| = 1} |\bar A_{n,k} x| \\
      &\geq&
      \max_{|x| = 1}
      \left|
        \sum_{i=1}^d \left(\sum_{j=1}^d L_k x_j \right)^2
      \right|^{1/2} \\
      &\geq& L_k d^{1/2}
    \end{eqnarray*}
    Hence for any $k < \infty$,
    \begin{eqnarray*}
      {1 \over n}
      \log \E
      \|\bar A_{n,k} \cdots \bar A_{1,k}\|^{-\alpha}
      &\leq&
             {1 \over n} \log \E \left(
             C^{-\alpha(n-1)} \prod_{i=1}^n \|\bar A_{i,k}\|^{-\alpha}
             \right) \\
      &=& {1 \over n} \left[
          -\alpha(n-1) \log C
          + \sum_{i=1}^n \log \E \|\bar A_{i,k}\|^{-\alpha}
          \right] \\
      &\leq&
          -{n - 1 \over n} \alpha \log C
          -\alpha \log (L_k d^{1/2})
    \end{eqnarray*}
    where $C < 1$ is some constant. Cearly the RHS tends to a constant
    as $n \to \infty$. Define
    \begin{equation*}
      \bar \Lambda_{k}(-\alpha) = \sup_{n \geq 1} {1 \over n} \log
      \E\|\bar A_{n,k} \cdots \bar A_{1,k}\|^{-\alpha}
    \end{equation*}
    Since
    \begin{equation*}
      \|\bar A_{n,k} \cdots \bar A_{1,k}\|^{-\alpha}
      \geq
      \|\bar A_{n,k} \cdots \bar A_{i,k}\|^{-\alpha}
      \|\bar A_{n,i-1} \cdots \bar A_{1,k}\|^{-\alpha}
    \end{equation*}
    By Fekete's lemma
    \begin{equation*}
      {1 \over n} \log \E \|\bar A_{n,k} \cdots \bar A_{1,k}\|^{-\alpha}
      \to
      \bar \Lambda_{k}(-\alpha)
    \end{equation*}
    Now consider
    \begin{eqnarray*}
      \bar g_k(\xi) = \sum_{n=0}^\infty
      (\E |\bar A_{n,k} \cdots \bar A_{1,k} X_0|^{-s\xi}
      \1{n \leq \bar T_u < \bar \tau}
      \I_{F_n}
      )^{1/s}
    \end{eqnarray*}
    where $\bar T_u$ and $\bar \tau$ are defined analogously. Changing
    to the $-s\xi$-shifted measure, we obtain
    \begin{eqnarray*}
      \bar g_k(\xi) &=& \sum_{n=0}^\infty \bar \lambda_{k}(-s\xi)^{n/s}
      (\E_{-s\xi} \1{n \leq \bar T_u < \bar \tau} \I_{F_n})^{1/s} \\
      &\leq&
      \sum_{n=0}^\infty \bar \lambda_{k}(-s\xi)^{n/s}
      [\P_{-s\xi}(n \leq \bar T_u < \bar \tau)]^{1/s}
    \end{eqnarray*}
    Applying \eqref{eq:ret_time} with $\beta = -s\xi$ gives
    \begin{eqnarray*}
      \P_{-s\xi}(\bar \tau > n) \leq a [\delta \bar \lambda_{k, -s\xi}(\alpha)]^{n-1}
    \end{eqnarray*}
    for some $a > 0$ and all $\delta > 1$ such that
    $\delta \lambda_k(\alpha - s\xi) < 1$. So we have
    \begin{eqnarray*}
      \bar g_k(\xi) &\leq& 1 + a \bar \lambda_k(-s\xi)\sum_{n=1}^\infty
      [\delta \bar \lambda_{k, -s\xi}(\alpha) \bar \lambda_k(-s\xi)]^{n-1} 
    \end{eqnarray*}
    Note
    \begin{eqnarray*}
      \bar \lambda_{k, -s\xi}(\alpha)
      \leq
      \E_{-s\xi} \bar A_{1,k}^\alpha 
      = {
        \E \bar A_{1,k}^{\alpha - s\xi}
        \over
        \E \bar A_{1,k}^{-s\xi}
      }
      = {
        \bar \lambda_k(\alpha - s\xi)
        \over
        \bar \lambda_k(-s\xi)
      }
    \end{eqnarray*}
    It follows
    \begin{eqnarray*}
      \bar g_k(\xi) &\leq& 1 + \sum_{n=1}^\infty
      [\delta \bar \lambda_k(\alpha - s\xi)]^{(n-1)/s}
      < \infty
    \end{eqnarray*}
    As $k \to \infty$, $\bar g_k(\xi)$ tends to the LHS of
    \eqref{eq:sum_on_F_n} and
    \[
    \delta \bar \lambda_k(\alpha - s\xi) \to \delta \lambda(\alpha - s\xi)
    < 1
    \]
    Thus we conclude \eqref{eq:sum_on_F_n} holds.
    \end{enumerate}
\end{proof}

\section{Examples}
\subsection{GARCH(2, 1)}
Here we consider the GARCH(2, 1) model described by
\begin{eqnarray*}
  \begin{pmatrix}
    \sigma_{t+1}^2 \\
    R_t^2 \\
  \end{pmatrix}
  =
  \begin{pmatrix}
    \alpha_1 z_t^2 + \beta_1 & \alpha_2 \\
    z_t^2 & 0 \\
  \end{pmatrix}
  \begin{pmatrix}
    \sigma_t^2 \\
    R_{t-1}^2 \\
  \end{pmatrix}
\end{eqnarray*}

We show that the Markov chain $(\sigma_{t+1}^2, R_t^2)$ satisfies a
minorization condition for a set $C = [a, b] \times [c, d]$ where
$a,b,c,d > 0$, and $\forall (x_0, y_0) \in C$
\begin{eqnarray}
  && P[(x_0, y_0), I_1 \times I_2] \nonumber \\
  &=& \P \left[
      (\sigma_{t+1}^2, R_t^2) \in I_1 \times I_2 |
      (\sigma_{t}^2, R_{t-1}^2) = (x_0, y_0)
      \right] \nonumber \\
  &\geq& \delta' \I_{C}(x_0, y_0) \nu(I_1 \times I_2) \label{eq:Minor}
\end{eqnarray}
where $\delta'$ is a constant and $\nu(\cdot)$ is a measure satsifying
$\nu(C) = 1$.
\begin{proof}
  First observe
  \begin{eqnarray*}
    && P[(x_0, y_0), I_1 \times I_2] \\
    &=& \int_{I_1} \int_{I_2}
        \delta \left[
        \alpha_1 x + \beta_1 x_0 + \alpha_2 y_0 - y
        \right]
        f_{x_0 Z^2}(x) dx dy
  \end{eqnarray*}
  where $\delta(\cdot)$ is the Dirac-$\delta$ function.
  Simplifying the above equation gives
  \begin{eqnarray*}
    && P[(x_0, y_0), I_1 \times I_2] \\
    &=& \int_{I_1/x_0} \I_{I_2}(\alpha_1 x_0 z^2 + \beta_1 x_0 +
        \alpha_2 y_0) f_Z^2 (z^2) dz^2
  \end{eqnarray*}
  Define mapping
  \begin{equation*}
    g(s, x, y): s \rightarrow {s \over \alpha_1 x}
    - \left(
      {\alpha_2 \over \alpha_1} {y \over x} + {\beta_1 \over \alpha_1}
    \right)
  \end{equation*}
  for $s \in (\alpha_2 y + \beta_1 x, \infty)$ and $x, y
  \in \mathbb R_+$. Then we may write
  \begin{eqnarray*}
    && P[(x_0, y_0), I_1 \times I_2] \\
    &=& \int_{I_1 / x_0 \cap g(I_2, x_0, y_0)} f_{Z^2}(z^2) dz^2
  \end{eqnarray*}
  Define a subset $h(I_2)$ of $I_2$:
  \[
  h(I_2) = I_2 \cap (\alpha_2 d, \infty)
  \]
  Note if $h(I_2) \neq \emptyset$ then $\forall s \in h(I_2)$ and $\forall
  y \in [c, d]$
  \begin{equation}
    \label{eq:der_g}
    \pd{g(s, x, y)}{x} < 0    
  \end{equation}
  So we have
  \begin{eqnarray*}
    && P[(x_0, y_0), I_1 \times I_2] \\
    &\geq& \int_{I_1/x_0 \cap g(h(I_2), x_0, y_0)} f_{Z^2}(z^2) dz^2
  \end{eqnarray*}
  Since $Z^2 \sim \chi^2(1)$, $f_{Z^2}(z^2)$ is monotonically
  decreasing. Meanwhile, $\L g(h(I_2), x_0, y_0)$, the Lebesgue measure
  of $g(h(I_2), x_0, y_0)$ is the smallest when $x_0$ is the
  largest possible, i.e. $b$. Furthermore, \eqref{eq:der_g} shows
  \[
  \arg \max_{x \in [a, b]} g(s, x, y) = a
  \]
  Hence
  \begin{eqnarray*}
    && \int_{I_1/x_0 \cap g(h(I_2), x_0, y_0)} f_{Z^2}(z^2) dz^2 \\
    &\geq& \int_{J(I_1, I_2)} f_{Z^2}(z^2) dz^2           
  \end{eqnarray*}
  where $J(I_1, I_2) := \emptyset$ if $I_1 = \emptyset$ or $h(I_2) =
  \emptyset$; otherwise
  \begin{eqnarray*}
  && J(I_1, I_2) \\
  &:=& [\max I_1/a - \L I_1/b, \max I_1/a]
      \cap \\
  && [g(\max h(I_2), a, c) - \L h(I_2) /\alpha_1 b, g(\max h(I_2), a, c)]
  \end{eqnarray*}
  Clearly
  \begin{eqnarray*}
    && \int_{J(I_1, I_2)} f_{Z^2}(z^2) dz^2               \\
    &\geq& \int_{J(I_1, I_2) \cap J([a, b], [c, d])} f_{Z^2}(z^2)
           dz^2 \\
    &\geq& f_{Z^2}(\max J([a, b], [c, d])) \L J([a, b], [c, d])
           {
           \L \left(
           J(I_1, I_2) \cap J([a, b], [c, d])
           \right)
           \over
           \L J([a, b], [c, d])
           }
  \end{eqnarray*}
  Thus \eqref{eq:Minor} is satisfied with
  \begin{eqnarray}
    \delta'
    &=&
    f_{Z^2}(\max J([a, b], [c, d])) \L J([a, b], [c, d]) \label{eq:regen_prob}\\
    \nu(I_1 \times I_2)
    &=& {
      \L \left(
        J(I_1, I_2) \cap J([a, b], [c, d])
      \right)
      \over
      \L J([a, b], [c, d])
    } \nonumber
  \end{eqnarray}
\end{proof}
From \eqref{eq:regen_prob} it immediately follows that $\delta'$ is
maximized by $J([a, b], [c ,d])$ satisfying
\begin{eqnarray}
  x_\M &=& {
    1 + x_\m + \sqrt{x_\m^2 + 6 x_\m + 1}
    \over
    2
  } \label{eq:maximizing_cond}
\end{eqnarray}
where 
\begin{eqnarray*}
  x_\M &=& \max J([a, b], [c ,d]) \\
  x_\m &=& \min J([a, b], [c ,d])
\end{eqnarray*}
Since
\[
J([a. b], [c, d]) =
\left[
  {b \over a} + {a \over b} - 1, {b \over a}
\right] \bigcap \left[
  {d - \alpha_2 c \over \alpha_1 a} - {\beta_1 \over \alpha_1} -
  {d \over \alpha_1 b} + {\alpha_2 d \wedge c \over \alpha_1 b},
  {d - \alpha_2 c \over \alpha_1 a} - {\beta_1 \over \alpha_1}  
\right]
\]
One way to choose $a, b, c, d$ so as to maximize $\delta'$ is to first
choose $c = 0$ and then choose $a, b$ so that
\eqref{eq:maximizing_cond} is satisfied by $b/a + a/b - 1$ and $b/a$
as $x_\m$ and $x_\M$ respectively. Finally choose
\[
  \alpha_1 b + \beta_1 a
  \leq
  d
  \leq
  \alpha_1 {
    a^2 - ab + b^2
    \over
    b - a
  } +
  \beta_1 {
    ab \over b - a
  }
\]
It is easily verified that the above interval for $d$ has length
${a^2 \over b - a} (\alpha_1 + \beta_1) > 0$. With such choices
\[
J([a. b], [c, d]) =
\left[
  {b \over a} + {a \over b} - 1, {b \over a}
\right]
\]
If $b/a$ is chosen to be the root of
\[
x^4 - 9x^2 + 6x - 6 = 0
\]
in the interval $(1, \infty)$, $b/a + a/b - 1$ and $b/a$ satisfy
\eqref{eq:maximizing_cond}. Figure \ref{fig:A} shows the function
$f(x) = x^4 - 9x^2 + 6x - 6$ in $(1, \infty)$.
\begin{figure}[htb!]
  \centering
  \includegraphics[scale=0.4]{argmax_b_over_a.pdf}
  \caption{Graph of $f(x) = x^4 - 9x^2 + 6x - 6$}
  \label{fig:A}
\end{figure}
\bibliographystyle{unsrt}
\bibliography{../../thesis/econophysics}
\end{document}
